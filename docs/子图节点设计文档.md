# å­å›¾èŠ‚ç‚¹è®¾è®¡æ–‡æ¡£

## æ–‡æ¡£ç‰ˆæœ¬
- **ç‰ˆæœ¬**: v1.0
- **æ—¥æœŸ**: 2026-02-09
- **çŠ¶æ€**: è®¾è®¡é˜¶æ®µ

## ç›®å½•
1. [æ¦‚è¿°](#1-æ¦‚è¿°)
2. [å­å›¾æ‰§è¡Œå™¨è®¾è®¡](#2-å­å›¾æ‰§è¡Œå™¨è®¾è®¡)
3. [Iteration èŠ‚ç‚¹](#3-iteration-èŠ‚ç‚¹)
4. [Loop èŠ‚ç‚¹](#4-loop-èŠ‚ç‚¹)
5. [List Operator èŠ‚ç‚¹](#5-list-operator-èŠ‚ç‚¹)
6. [ä½œç”¨åŸŸç®¡ç†](#6-ä½œç”¨åŸŸç®¡ç†)
7. [å¹¶è¡Œæ‰§è¡Œ](#7-å¹¶è¡Œæ‰§è¡Œ)
8. [æµ‹è¯•ç­–ç•¥](#8-æµ‹è¯•ç­–ç•¥)

---

## 1. æ¦‚è¿°

### 1.1 ç›®æ ‡

è®¾è®¡å’Œå®ç°ä¸‰ä¸ªåŒ…å«å­å›¾æ‰§è¡Œé€»è¾‘çš„æ§åˆ¶æµèŠ‚ç‚¹ï¼š
- **Iteration**: éå†æ•°ç»„ï¼Œå¯¹æ¯ä¸ªå…ƒç´ æ‰§è¡Œå­å›¾
- **Loop**: æ¡ä»¶å¾ªç¯ï¼Œæ»¡è¶³æ¡ä»¶æ—¶é‡å¤æ‰§è¡Œå­å›¾
- **List Operator**: åˆ—è¡¨æ“ä½œï¼ˆè¿‡æ»¤ã€æ˜ å°„ã€æ’åºç­‰ï¼‰

### 1.2 å…±åŒç‰¹ç‚¹

- âœ… **ä¸ä¾èµ–å¤–éƒ¨æœåŠ¡**: çº¯æœ¬åœ°æ‰§è¡Œ
- ğŸ”„ **å­å›¾æ‰§è¡Œ**: åŒ…å«åµŒå¥—çš„èŠ‚ç‚¹å’Œè¾¹
- ğŸ“¦ **ä½œç”¨åŸŸéš”ç¦»**: å­å›¾æœ‰ç‹¬ç«‹çš„å˜é‡ä½œç”¨åŸŸ
- âš¡ **å¹¶è¡Œæ”¯æŒ**: æ”¯æŒå¹¶è¡Œæ‰§è¡Œå¤šä¸ªå­å›¾å®ä¾‹

### 1.3 èŠ‚ç‚¹å¯¹æ¯”

| èŠ‚ç‚¹ | è¾“å…¥ | æ‰§è¡Œæ–¹å¼ | è¾“å‡º |
|------|------|---------|------|
| **Iteration** | æ•°ç»„ | å¯¹æ¯ä¸ªå…ƒç´ æ‰§è¡Œå­å›¾ | ç»“æœæ•°ç»„ |
| **Loop** | æ¡ä»¶ | æ¡ä»¶ä¸ºçœŸæ—¶é‡å¤æ‰§è¡Œ | æœ€ç»ˆç»“æœ |
| **List Operator** | æ•°ç»„ | å¯¹æ•°ç»„è¿›è¡Œæ“ä½œ | å¤„ç†åçš„æ•°ç»„ |

---

## 2. å­å›¾æ‰§è¡Œå™¨è®¾è®¡

### 2.1 SubGraphExecutor

æ‰€æœ‰åŒ…å«å­å›¾çš„èŠ‚ç‚¹å…±äº«ä¸€ä¸ªå­å›¾æ‰§è¡Œå™¨ï¼š

```rust
/// å­å›¾æ‰§è¡Œå™¨
pub struct SubGraphExecutor {
    /// èŠ‚ç‚¹æ³¨å†Œè¡¨
    node_registry: Arc<NodeRegistry>,
}

impl SubGraphExecutor {
    pub fn new(node_registry: Arc<NodeRegistry>) -> Self {
        Self { node_registry }
    }

    /// æ‰§è¡Œå­å›¾
    ///
    /// # å‚æ•°
    /// - `sub_graph`: å­å›¾å®šä¹‰ï¼ˆèŠ‚ç‚¹å’Œè¾¹ï¼‰
    /// - `parent_pool`: çˆ¶çº§å˜é‡æ± 
    /// - `scope_vars`: å½“å‰ä½œç”¨åŸŸçš„å±€éƒ¨å˜é‡
    /// - `event_sender`: äº‹ä»¶å‘é€å™¨
    ///
    /// # è¿”å›
    /// - å­å›¾æ‰§è¡Œç»“æœ
    pub async fn execute(
        &self,
        sub_graph: &SubGraphDefinition,
        parent_pool: &Arc<RwLock<VariablePool>>,
        scope_vars: HashMap<String, Value>,
        event_sender: &EventSender,
    ) -> Result<Value, SubGraphError> {
        // 1. åˆ›å»ºå­ä½œç”¨åŸŸ
        let scoped_pool = self.create_scoped_pool(parent_pool, scope_vars).await?;

        // 2. æ„å»ºå­å›¾
        let sub_definition = self.build_sub_definition(sub_graph)?;

        // 3. åˆ›å»ºå­è¿è¡Œæ—¶
        let sub_runtime = SubGraphRuntime::new(
            sub_definition,
            scoped_pool,
            event_sender.clone(),
        );

        // 4. æ‰§è¡Œå­å›¾
        let result = self.run_sub_graph(sub_runtime).await?;

        Ok(result)
    }

    /// åˆ›å»ºå¸¦ä½œç”¨åŸŸçš„å˜é‡æ± 
    async fn create_scoped_pool(
        &self,
        parent_pool: &Arc<RwLock<VariablePool>>,
        scope_vars: HashMap<String, Value>,
    ) -> Result<Arc<RwLock<VariablePool>>, SubGraphError> {
        let mut pool = parent_pool.write().await;

        // åˆ›å»ºæ–°ä½œç”¨åŸŸ
        let scope_id = uuid::Uuid::new_v4().to_string();
        pool.push_scope(scope_id, scope_vars);

        Ok(parent_pool.clone())
    }

    /// æ„å»ºå­å›¾å®šä¹‰
    fn build_sub_definition(
        &self,
        sub_graph: &SubGraphDefinition,
    ) -> Result<WorkflowDefinition, SubGraphError> {
        // ä»å­å›¾èŠ‚ç‚¹å’Œè¾¹æ„å»º petgraph
        let mut graph = StableDiGraph::new();
        let mut node_indices = HashMap::new();

        // æ·»åŠ èŠ‚ç‚¹
        for node in &sub_graph.nodes {
            let idx = graph.add_node(GraphNode {
                id: node.id.clone(),
                node_type: node.node_type.clone(),
                config: node.data.clone(),
                title: node.title.clone(),
            });
            node_indices.insert(node.id.clone(), idx);
        }

        // æ·»åŠ è¾¹
        for edge in &sub_graph.edges {
            let source_idx = node_indices.get(&edge.source)
                .ok_or(SubGraphError::InvalidEdge)?;
            let target_idx = node_indices.get(&edge.target)
                .ok_or(SubGraphError::InvalidEdge)?;

            graph.add_edge(*source_idx, *target_idx, GraphEdge {
                id: edge.id.clone(),
                source: edge.source.clone(),
                target: edge.target.clone(),
                edge_type: EdgeType::Normal,
            });
        }

        // æ‰¾åˆ°å¼€å§‹èŠ‚ç‚¹
        let start_node_id = sub_graph.nodes.iter()
            .find(|n| n.node_type == "start")
            .map(|n| node_indices[&n.id])
            .ok_or(SubGraphError::NoStartNode)?;

        Ok(WorkflowDefinition {
            id: uuid::Uuid::new_v4().to_string(),
            name: "sub_graph".to_string(),
            graph,
            start_node_id,
            metadata: WorkflowMetadata::default(),
        })
    }

    /// è¿è¡Œå­å›¾
    async fn run_sub_graph(
        &self,
        runtime: SubGraphRuntime,
    ) -> Result<Value, SubGraphError> {
        // åˆ›å»ºå­è°ƒåº¦å™¨
        let mut dispatcher = SubGraphDispatcher::new(
            runtime,
            self.node_registry.clone(),
        );

        // æ‰§è¡Œå¹¶è¿”å›ç»“æœ
        dispatcher.run().await
    }
}
```

### 2.2 SubGraphDefinition

```rust
/// å­å›¾å®šä¹‰
#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct SubGraphDefinition {
    /// å­å›¾èŠ‚ç‚¹
    pub nodes: Vec<NodeSchema>,

    /// å­å›¾è¾¹
    pub edges: Vec<EdgeSchema>,
}
```

### 2.3 SubGraphError

```rust
#[derive(Debug, thiserror::Error)]
pub enum SubGraphError {
    #[error("Invalid edge reference")]
    InvalidEdge,

    #[error("No start node found in sub-graph")]
    NoStartNode,

    #[error("No end node found in sub-graph")]
    NoEndNode,

    #[error("Sub-graph execution failed: {0}")]
    ExecutionFailed(String),

    #[error("Max iterations exceeded: {0}")]
    MaxIterationsExceeded(usize),

    #[error("Scope error: {0}")]
    ScopeError(String),
}
```

---

## 3. Iteration èŠ‚ç‚¹

### 3.1 åŠŸèƒ½è¯´æ˜

Iteration èŠ‚ç‚¹éå†è¾“å…¥æ•°ç»„ï¼Œå¯¹æ¯ä¸ªå…ƒç´ æ‰§è¡Œå­å›¾ï¼Œæ”¶é›†æ‰€æœ‰ç»“æœã€‚

```
è¾“å…¥: [item1, item2, item3]
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Iteration Node                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ å­å›¾æ‰§è¡Œ (item1)            â”‚  â”‚ â†’ result1
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ å­å›¾æ‰§è¡Œ (item2)            â”‚  â”‚ â†’ result2
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ å­å›¾æ‰§è¡Œ (item3)            â”‚  â”‚ â†’ result3
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
è¾“å‡º: [result1, result2, result3]
```

### 3.2 DSL é…ç½®

```yaml
- id: iteration_1
  type: iteration
  data:
    # è¾“å…¥æ•°ç»„çš„å˜é‡é€‰æ‹©å™¨
    input_selector: "input.items"

    # æ˜¯å¦å¹¶è¡Œæ‰§è¡Œ
    parallel: true

    # å¹¶è¡Œåº¦ï¼ˆæœ€å¤§å¹¶å‘æ•°ï¼‰
    parallelism: 10

    # å­å›¾å®šä¹‰
    sub_graph:
      nodes:
        - id: sub_start
          type: start
          data: {}
        - id: process
          type: template
          data:
            template: "Processed: {{item}}"
        - id: sub_end
          type: end
          data:
            outputs:
              - name: result
                variable_selector: "process.output"
      edges:
        - id: e1
          source: sub_start
          target: process
        - id: e2
          source: process
          target: sub_end

    # è¾“å‡ºå˜é‡å
    output_variable: "results"
```

### 3.3 é…ç½®ç»“æ„

```rust
#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct IterationNodeConfig {
    /// è¾“å…¥æ•°ç»„çš„å˜é‡é€‰æ‹©å™¨
    pub input_selector: String,

    /// æ˜¯å¦å¹¶è¡Œæ‰§è¡Œ
    #[serde(default)]
    pub parallel: bool,

    /// å¹¶è¡Œåº¦ï¼ˆæœ€å¤§å¹¶å‘æ•°ï¼‰
    #[serde(default = "default_parallelism")]
    pub parallelism: usize,

    /// å­å›¾å®šä¹‰
    pub sub_graph: SubGraphDefinition,

    /// è¾“å‡ºå˜é‡å
    pub output_variable: String,

    /// æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼ˆé˜²æ­¢æ— é™å¾ªç¯ï¼‰
    #[serde(default = "default_max_iterations")]
    pub max_iterations: usize,
}

fn default_parallelism() -> usize { 10 }
fn default_max_iterations() -> usize { 1000 }
```

### 3.4 èŠ‚ç‚¹å®ç°

```rust
pub struct IterationNodeExecutor {
    sub_graph_executor: Arc<SubGraphExecutor>,
}

impl IterationNodeExecutor {
    pub fn new(node_registry: Arc<NodeRegistry>) -> Self {
        Self {
            sub_graph_executor: Arc::new(SubGraphExecutor::new(node_registry)),
        }
    }
}

#[async_trait]
impl NodeExecutor for IterationNodeExecutor {
    fn validate(&self, config: &Value) -> Result<(), NodeError> {
        let config: IterationNodeConfig = serde_json::from_value(config.clone())?;

        // éªŒè¯å­å›¾æœ‰ start å’Œ end èŠ‚ç‚¹
        let has_start = config.sub_graph.nodes.iter()
            .any(|n| n.node_type == "start");
        let has_end = config.sub_graph.nodes.iter()
            .any(|n| n.node_type == "end");

        if !has_start {
            return Err(NodeError::ConfigError("Sub-graph must have a start node".to_string()));
        }
        if !has_end {
            return Err(NodeError::ConfigError("Sub-graph must have an end node".to_string()));
        }

        Ok(())
    }

    async fn execute(
        &self,
        ctx: &NodeContext,
        pool: &Arc<RwLock<VariablePool>>,
        event_sender: &EventSender,
    ) -> Result<NodeExecutionResult, NodeError> {
        let config: IterationNodeConfig = serde_json::from_value(ctx.config.clone())?;

        // 1. è·å–è¾“å…¥æ•°ç»„
        let pool_read = pool.read().await;
        let input_array = pool_read.get_value(&config.input_selector)
            .ok_or_else(|| NodeError::VariableNotFound(config.input_selector.clone()))?;
        drop(pool_read);

        let items = input_array.as_array()
            .ok_or_else(|| NodeError::TypeError("Input must be an array".to_string()))?;

        // 2. æ£€æŸ¥æœ€å¤§è¿­ä»£æ¬¡æ•°
        if items.len() > config.max_iterations {
            return Err(NodeError::ExecutionError(
                format!("Array size {} exceeds max iterations {}", items.len(), config.max_iterations)
            ));
        }

        // 3. æ‰§è¡Œè¿­ä»£
        let results = if config.parallel {
            self.execute_parallel(
                &config,
                items,
                pool,
                event_sender,
            ).await?
        } else {
            self.execute_sequential(
                &config,
                items,
                pool,
                event_sender,
            ).await?
        };

        // 4. è¿”å›ç»“æœ
        Ok(NodeExecutionResult::Completed(json!({
            config.output_variable: results,
        })))
    }

    fn node_type(&self) -> &str {
        "iteration"
    }
}

impl IterationNodeExecutor {
    /// ä¸²è¡Œæ‰§è¡Œ
    async fn execute_sequential(
        &self,
        config: &IterationNodeConfig,
        items: &[Value],
        pool: &Arc<RwLock<VariablePool>>,
        event_sender: &EventSender,
    ) -> Result<Vec<Value>, NodeError> {
        let mut results = Vec::with_capacity(items.len());

        for (index, item) in items.iter().enumerate() {
            // åˆ›å»ºä½œç”¨åŸŸå˜é‡
            let scope_vars = hashmap! {
                "item".to_string() => item.clone(),
                "index".to_string() => json!(index),
            };

            // æ‰§è¡Œå­å›¾
            let result = self.sub_graph_executor.execute(
                &config.sub_graph,
                pool,
                scope_vars,
                event_sender,
            ).await.map_err(|e| NodeError::ExecutionError(e.to_string()))?;

            results.push(result);
        }

        Ok(results)
    }

    /// å¹¶è¡Œæ‰§è¡Œ
    async fn execute_parallel(
        &self,
        config: &IterationNodeConfig,
        items: &[Value],
        pool: &Arc<RwLock<VariablePool>>,
        event_sender: &EventSender,
    ) -> Result<Vec<Value>, NodeError> {
        use tokio::sync::Semaphore;

        // ä½¿ç”¨ä¿¡å·é‡é™åˆ¶å¹¶å‘æ•°
        let semaphore = Arc::new(Semaphore::new(config.parallelism));
        let mut tasks = Vec::with_capacity(items.len());

        for (index, item) in items.iter().enumerate() {
            let permit = semaphore.clone().acquire_owned().await.unwrap();
            let executor = self.sub_graph_executor.clone();
            let sub_graph = config.sub_graph.clone();
            let pool_clone = pool.clone();
            let event_sender_clone = event_sender.clone();
            let item_clone = item.clone();

            let task = tokio::spawn(async move {
                let scope_vars = hashmap! {
                    "item".to_string() => item_clone,
                    "index".to_string() => json!(index),
                };

                let result = executor.execute(
                    &sub_graph,
                    &pool_clone,
                    scope_vars,
                    &event_sender_clone,
                ).await;

                drop(permit);  // é‡Šæ”¾ä¿¡å·é‡
                (index, result)
            });

            tasks.push(task);
        }

        // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        let mut results = vec![Value::Null; items.len()];
        for task in tasks {
            let (index, result) = task.await
                .map_err(|e| NodeError::ExecutionError(e.to_string()))?;

            results[index] = result
                .map_err(|e| NodeError::ExecutionError(e.to_string()))?;
        }

        Ok(results)
    }
}
```

---

## 4. Loop èŠ‚ç‚¹

### 4.1 åŠŸèƒ½è¯´æ˜

Loop èŠ‚ç‚¹åœ¨æ¡ä»¶ä¸ºçœŸæ—¶é‡å¤æ‰§è¡Œå­å›¾ï¼Œç›´åˆ°æ¡ä»¶ä¸ºå‡æˆ–è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ã€‚

```
åˆå§‹çŠ¶æ€
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Loop Node                        â”‚
â”‚                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ æ£€æŸ¥æ¡ä»¶                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â†“ (æ¡ä»¶ä¸ºçœŸ)              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ æ‰§è¡Œå­å›¾                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â†“                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ æ›´æ–°å¾ªç¯å˜é‡                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â†“ (ç»§ç»­å¾ªç¯)              â”‚
â”‚         â†‘â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚                                   â”‚
â”‚         â†“ (æ¡ä»¶ä¸ºå‡)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
è¾“å‡ºæœ€ç»ˆç»“æœ
```

### 4.2 DSL é…ç½®

```yaml
- id: loop_1
  type: loop
  data:
    # å¾ªç¯æ¡ä»¶
    condition:
      variable_selector: "loop.counter"
      comparison_operator: "less_than"
      value: 10

    # æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼ˆå®‰å…¨é™åˆ¶ï¼‰
    max_iterations: 100

    # å¾ªç¯å˜é‡åˆå§‹å€¼
    initial_vars:
      counter: 0
      accumulator: 0

    # å­å›¾å®šä¹‰
    sub_graph:
      nodes:
        - id: sub_start
          type: start
          data: {}
        - id: process
          type: code
          data:
            language: javascript
            code: |
              function main(inputs) {
                return {
                  counter: inputs.counter + 1,
                  accumulator: inputs.accumulator + inputs.counter
                };
              }
            inputs:
              counter: "loop.counter"
              accumulator: "loop.accumulator"
            output_variable: "result"
        - id: sub_end
          type: end
          data:
            outputs:
              - name: counter
                variable_selector: "process.result.counter"
              - name: accumulator
                variable_selector: "process.result.accumulator"
      edges:
        - id: e1
          source: sub_start
          target: process
        - id: e2
          source: process
          target: sub_end

    # è¾“å‡ºå˜é‡å
    output_variable: "loop_result"
```

### 4.3 é…ç½®ç»“æ„

```rust
#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct LoopNodeConfig {
    /// å¾ªç¯æ¡ä»¶
    pub condition: LoopCondition,

    /// æœ€å¤§è¿­ä»£æ¬¡æ•°
    #[serde(default = "default_max_iterations")]
    pub max_iterations: usize,

    /// å¾ªç¯å˜é‡åˆå§‹å€¼
    #[serde(default)]
    pub initial_vars: HashMap<String, Value>,

    /// å­å›¾å®šä¹‰
    pub sub_graph: SubGraphDefinition,

    /// è¾“å‡ºå˜é‡å
    pub output_variable: String,
}

#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct LoopCondition {
    /// å˜é‡é€‰æ‹©å™¨
    pub variable_selector: String,

    /// æ¯”è¾ƒè¿ç®—ç¬¦
    pub comparison_operator: ComparisonOperator,

    /// æ¯”è¾ƒå€¼
    pub value: Value,
}

fn default_max_iterations() -> usize { 100 }
```

### 4.4 èŠ‚ç‚¹å®ç°

```rust
pub struct LoopNodeExecutor {
    sub_graph_executor: Arc<SubGraphExecutor>,
    condition_evaluator: Arc<ConditionEvaluator>,
}

impl LoopNodeExecutor {
    pub fn new(node_registry: Arc<NodeRegistry>) -> Self {
        Self {
            sub_graph_executor: Arc::new(SubGraphExecutor::new(node_registry)),
            condition_evaluator: Arc::new(ConditionEvaluator::new()),
        }
    }
}

#[async_trait]
impl NodeExecutor for LoopNodeExecutor {
    fn validate(&self, config: &Value) -> Result<(), NodeError> {
        let config: LoopNodeConfig = serde_json::from_value(config.clone())?;

        // éªŒè¯å­å›¾
        let has_start = config.sub_graph.nodes.iter()
            .any(|n| n.node_type == "start");
        let has_end = config.sub_graph.nodes.iter()
            .any(|n| n.node_type == "end");

        if !has_start || !has_end {
            return Err(NodeError::ConfigError(
                "Sub-graph must have start and end nodes".to_string()
            ));
        }

        // éªŒè¯æœ€å¤§è¿­ä»£æ¬¡æ•°
        if config.max_iterations == 0 {
            return Err(NodeError::ConfigError(
                "max_iterations must be greater than 0".to_string()
            ));
        }

        Ok(())
    }

    async fn execute(
        &self,
        ctx: &NodeContext,
        pool: &Arc<RwLock<VariablePool>>,
        event_sender: &EventSender,
    ) -> Result<NodeExecutionResult, NodeError> {
        let config: LoopNodeConfig = serde_json::from_value(ctx.config.clone())?;

        // 1. åˆå§‹åŒ–å¾ªç¯å˜é‡
        let mut loop_vars = config.initial_vars.clone();
        let mut iteration_count = 0;

        // 2. å¾ªç¯æ‰§è¡Œ
        loop {
            // æ£€æŸ¥æœ€å¤§è¿­ä»£æ¬¡æ•°
            if iteration_count >= config.max_iterations {
                return Err(NodeError::ExecutionError(
                    format!("Max iterations {} exceeded", config.max_iterations)
                ));
            }

            // è¯„ä¼°æ¡ä»¶
            let condition_value = self.get_condition_value(&config.condition, &loop_vars)?;
            let should_continue = self.condition_evaluator.evaluate(
                &condition_value,
                &config.condition.comparison_operator,
                &config.condition.value,
            )?;

            if !should_continue {
                break;
            }

            // åˆ›å»ºä½œç”¨åŸŸå˜é‡
            let mut scope_vars = loop_vars.clone();
            scope_vars.insert("_iteration".to_string(), json!(iteration_count));

            // æ‰§è¡Œå­å›¾
            let result = self.sub_graph_executor.execute(
                &config.sub_graph,
                pool,
                scope_vars,
                event_sender,
            ).await.map_err(|e| NodeError::ExecutionError(e.to_string()))?;

            // æ›´æ–°å¾ªç¯å˜é‡
            if let Some(obj) = result.as_object() {
                for (key, value) in obj {
                    loop_vars.insert(key.clone(), value.clone());
                }
            }

            iteration_count += 1;
        }

        // 3. è¿”å›æœ€ç»ˆç»“æœ
        Ok(NodeExecutionResult::Completed(json!({
            config.output_variable: loop_vars,
            "_iterations": iteration_count,
        })))
    }

    fn node_type(&self) -> &str {
        "loop"
    }
}

impl LoopNodeExecutor {
    fn get_condition_value(
        &self,
        condition: &LoopCondition,
        loop_vars: &HashMap<String, Value>,
    ) -> Result<Value, NodeError> {
        // è§£æå˜é‡é€‰æ‹©å™¨ï¼ˆå¦‚ "loop.counter"ï¼‰
        let parts: Vec<&str> = condition.variable_selector.split('.').collect();

        if parts.len() < 2 || parts[0] != "loop" {
            return Err(NodeError::ConfigError(
                "Condition variable_selector must start with 'loop.'".to_string()
            ));
        }

        let var_name = parts[1];
        loop_vars.get(var_name)
            .cloned()
            .ok_or_else(|| NodeError::VariableNotFound(var_name.to_string()))
    }
}
```

---

## 5. List Operator èŠ‚ç‚¹

### 5.1 åŠŸèƒ½è¯´æ˜

List Operator èŠ‚ç‚¹å¯¹åˆ—è¡¨è¿›è¡Œå„ç§æ“ä½œï¼ŒåŒ…æ‹¬è¿‡æ»¤ã€æ˜ å°„ã€æ’åºã€èšåˆç­‰ã€‚

```
è¾“å…¥: [item1, item2, item3, item4, item5]
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  List Operator Node               â”‚
â”‚                                   â”‚
â”‚  æ“ä½œç±»å‹:                        â”‚
â”‚  â€¢ filter: è¿‡æ»¤å…ƒç´                â”‚
â”‚  â€¢ map: æ˜ å°„è½¬æ¢                  â”‚
â”‚  â€¢ sort: æ’åº                     â”‚
â”‚  â€¢ slice: åˆ‡ç‰‡                    â”‚
â”‚  â€¢ first/last: å–é¦–/å°¾å…ƒç´         â”‚
â”‚  â€¢ flatten: å±•å¹³åµŒå¥—æ•°ç»„          â”‚
â”‚  â€¢ unique: å»é‡                   â”‚
â”‚  â€¢ reverse: åè½¬                  â”‚
â”‚  â€¢ concat: åˆå¹¶æ•°ç»„               â”‚
â”‚                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
è¾“å‡º: [å¤„ç†åçš„ç»“æœ]
```

### 5.2 DSL é…ç½®

```yaml
# è¿‡æ»¤æ“ä½œ
- id: list_filter
  type: list-operator
  data:
    operation: filter
    input_selector: "input.users"
    # è¿‡æ»¤æ¡ä»¶ï¼ˆä½¿ç”¨å­å›¾ï¼‰
    sub_graph:
      nodes:
        - id: sub_start
          type: start
        - id: check
          type: code
          data:
            language: javascript
            code: |
              function main(inputs) {
                return { keep: inputs.item.age >= 18 };
              }
            inputs:
              item: "item"
            output_variable: "result"
        - id: sub_end
          type: end
          data:
            outputs:
              - name: keep
                variable_selector: "check.result.keep"
      edges:
        - source: sub_start
          target: check
        - source: check
          target: sub_end
    output_variable: "adult_users"

# æ˜ å°„æ“ä½œ
- id: list_map
  type: list-operator
  data:
    operation: map
    input_selector: "input.numbers"
    sub_graph:
      nodes:
        - id: sub_start
          type: start
        - id: transform
          type: code
          data:
            language: javascript
            code: |
              function main(inputs) {
                return { value: inputs.item * 2 };
              }
            inputs:
              item: "item"
            output_variable: "result"
        - id: sub_end
          type: end
          data:
            outputs:
              - name: value
                variable_selector: "transform.result.value"
      edges:
        - source: sub_start
          target: transform
        - source: transform
          target: sub_end
    output_variable: "doubled"

# æ’åºæ“ä½œï¼ˆç®€å•æ¨¡å¼ï¼Œæ— å­å›¾ï¼‰
- id: list_sort
  type: list-operator
  data:
    operation: sort
    input_selector: "input.items"
    sort_key: "price"
    sort_order: "desc"
    output_variable: "sorted_items"

# åˆ‡ç‰‡æ“ä½œ
- id: list_slice
  type: list-operator
  data:
    operation: slice
    input_selector: "input.items"
    start: 0
    end: 10
    output_variable: "first_10"

# èšåˆæ“ä½œ
- id: list_reduce
  type: list-operator
  data:
    operation: reduce
    input_selector: "input.numbers"
    initial_value: 0
    sub_graph:
      nodes:
        - id: sub_start
          type: start
        - id: accumulate
          type: code
          data:
            language: javascript
            code: |
              function main(inputs) {
                return { value: inputs.accumulator + inputs.item };
              }
            inputs:
              item: "item"
              accumulator: "accumulator"
            output_variable: "result"
        - id: sub_end
          type: end
          data:
            outputs:
              - name: value
                variable_selector: "accumulate.result.value"
      edges:
        - source: sub_start
          target: accumulate
        - source: accumulate
          target: sub_end
    output_variable: "sum"
```

### 5.3 é…ç½®ç»“æ„

```rust
#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct ListOperatorNodeConfig {
    /// æ“ä½œç±»å‹
    pub operation: ListOperation,

    /// è¾“å…¥æ•°ç»„çš„å˜é‡é€‰æ‹©å™¨
    pub input_selector: String,

    /// å­å›¾å®šä¹‰ï¼ˆç”¨äº filter, map, reduce ç­‰ï¼‰
    #[serde(default)]
    pub sub_graph: Option<SubGraphDefinition>,

    /// æ’åºé”®ï¼ˆç”¨äº sortï¼‰
    #[serde(default)]
    pub sort_key: Option<String>,

    /// æ’åºé¡ºåºï¼ˆç”¨äº sortï¼‰
    #[serde(default)]
    pub sort_order: Option<SortOrder>,

    /// åˆ‡ç‰‡èµ·å§‹ä½ç½®ï¼ˆç”¨äº sliceï¼‰
    #[serde(default)]
    pub start: Option<usize>,

    /// åˆ‡ç‰‡ç»“æŸä½ç½®ï¼ˆç”¨äº sliceï¼‰
    #[serde(default)]
    pub end: Option<usize>,

    /// åˆå§‹å€¼ï¼ˆç”¨äº reduceï¼‰
    #[serde(default)]
    pub initial_value: Option<Value>,

    /// ç¬¬äºŒä¸ªè¾“å…¥æ•°ç»„ï¼ˆç”¨äº concatï¼‰
    #[serde(default)]
    pub second_input_selector: Option<String>,

    /// æ˜¯å¦å¹¶è¡Œæ‰§è¡Œ
    #[serde(default)]
    pub parallel: bool,

    /// è¾“å‡ºå˜é‡å
    pub output_variable: String,
}

#[derive(Debug, Clone, Copy, Deserialize, Serialize, PartialEq, Eq)]
#[serde(rename_all = "snake_case")]
pub enum ListOperation {
    /// è¿‡æ»¤ï¼šä¿ç•™æ»¡è¶³æ¡ä»¶çš„å…ƒç´ 
    Filter,
    /// æ˜ å°„ï¼šè½¬æ¢æ¯ä¸ªå…ƒç´ 
    Map,
    /// æ’åº
    Sort,
    /// åˆ‡ç‰‡
    Slice,
    /// å–ç¬¬ä¸€ä¸ªå…ƒç´ 
    First,
    /// å–æœ€åä¸€ä¸ªå…ƒç´ 
    Last,
    /// å±•å¹³åµŒå¥—æ•°ç»„
    Flatten,
    /// å»é‡
    Unique,
    /// åè½¬
    Reverse,
    /// åˆå¹¶æ•°ç»„
    Concat,
    /// èšåˆ
    Reduce,
    /// è·å–é•¿åº¦
    Length,
}

#[derive(Debug, Clone, Copy, Deserialize, Serialize, PartialEq, Eq)]
#[serde(rename_all = "snake_case")]
pub enum SortOrder {
    Asc,
    Desc,
}
```

### 5.4 èŠ‚ç‚¹å®ç°

```rust
pub struct ListOperatorNodeExecutor {
    sub_graph_executor: Arc<SubGraphExecutor>,
}

impl ListOperatorNodeExecutor {
    pub fn new(node_registry: Arc<NodeRegistry>) -> Self {
        Self {
            sub_graph_executor: Arc::new(SubGraphExecutor::new(node_registry)),
        }
    }
}

#[async_trait]
impl NodeExecutor for ListOperatorNodeExecutor {
    fn validate(&self, config: &Value) -> Result<(), NodeError> {
        let config: ListOperatorNodeConfig = serde_json::from_value(config.clone())?;

        // éªŒè¯éœ€è¦å­å›¾çš„æ“ä½œ
        match config.operation {
            ListOperation::Filter | ListOperation::Map | ListOperation::Reduce => {
                if config.sub_graph.is_none() {
                    return Err(NodeError::ConfigError(
                        format!("{:?} operation requires sub_graph", config.operation)
                    ));
                }
            }
            ListOperation::Sort => {
                if config.sort_key.is_none() {
                    return Err(NodeError::ConfigError(
                        "Sort operation requires sort_key".to_string()
                    ));
                }
            }
            ListOperation::Slice => {
                if config.start.is_none() && config.end.is_none() {
                    return Err(NodeError::ConfigError(
                        "Slice operation requires start or end".to_string()
                    ));
                }
            }
            ListOperation::Concat => {
                if config.second_input_selector.is_none() {
                    return Err(NodeError::ConfigError(
                        "Concat operation requires second_input_selector".to_string()
                    ));
                }
            }
            _ => {}
        }

        Ok(())
    }

    async fn execute(
        &self,
        ctx: &NodeContext,
        pool: &Arc<RwLock<VariablePool>>,
        event_sender: &EventSender,
    ) -> Result<NodeExecutionResult, NodeError> {
        let config: ListOperatorNodeConfig = serde_json::from_value(ctx.config.clone())?;

        // è·å–è¾“å…¥æ•°ç»„
        let pool_read = pool.read().await;
        let input = pool_read.get_value(&config.input_selector)
            .ok_or_else(|| NodeError::VariableNotFound(config.input_selector.clone()))?;
        drop(pool_read);

        // æ ¹æ®æ“ä½œç±»å‹æ‰§è¡Œ
        let result = match config.operation {
            ListOperation::Filter => {
                self.execute_filter(&config, &input, pool, event_sender).await?
            }
            ListOperation::Map => {
                self.execute_map(&config, &input, pool, event_sender).await?
            }
            ListOperation::Sort => {
                self.execute_sort(&config, &input)?
            }
            ListOperation::Slice => {
                self.execute_slice(&config, &input)?
            }
            ListOperation::First => {
                self.execute_first(&input)?
            }
            ListOperation::Last => {
                self.execute_last(&input)?
            }
            ListOperation::Flatten => {
                self.execute_flatten(&input)?
            }
            ListOperation::Unique => {
                self.execute_unique(&input)?
            }
            ListOperation::Reverse => {
                self.execute_reverse(&input)?
            }
            ListOperation::Concat => {
                self.execute_concat(&config, &input, pool).await?
            }
            ListOperation::Reduce => {
                self.execute_reduce(&config, &input, pool, event_sender).await?
            }
            ListOperation::Length => {
                self.execute_length(&input)?
            }
        };

        Ok(NodeExecutionResult::Completed(json!({
            config.output_variable: result,
        })))
    }

    fn node_type(&self) -> &str {
        "list-operator"
    }
}

impl ListOperatorNodeExecutor {
    /// Filter æ“ä½œ
    async fn execute_filter(
        &self,
        config: &ListOperatorNodeConfig,
        input: &Value,
        pool: &Arc<RwLock<VariablePool>>,
        event_sender: &EventSender,
    ) -> Result<Value, NodeError> {
        let items = input.as_array()
            .ok_or_else(|| NodeError::TypeError("Input must be an array".to_string()))?;

        let sub_graph = config.sub_graph.as_ref().unwrap();
        let mut results = Vec::new();

        for (index, item) in items.iter().enumerate() {
            let scope_vars = hashmap! {
                "item".to_string() => item.clone(),
                "index".to_string() => json!(index),
            };

            let result = self.sub_graph_executor.execute(
                sub_graph,
                pool,
                scope_vars,
                event_sender,
            ).await.map_err(|e| NodeError::ExecutionError(e.to_string()))?;

            // æ£€æŸ¥æ˜¯å¦ä¿ç•™
            let keep = result.get("keep")
                .and_then(|v| v.as_bool())
                .unwrap_or(false);

            if keep {
                results.push(item.clone());
            }
        }

        Ok(json!(results))
    }

    /// Map æ“ä½œ
    async fn execute_map(
        &self,
        config: &ListOperatorNodeConfig,
        input: &Value,
        pool: &Arc<RwLock<VariablePool>>,
        event_sender: &EventSender,
    ) -> Result<Value, NodeError> {
        let items = input.as_array()
            .ok_or_else(|| NodeError::TypeError("Input must be an array".to_string()))?;

        let sub_graph = config.sub_graph.as_ref().unwrap();
        let mut results = Vec::with_capacity(items.len());

        for (index, item) in items.iter().enumerate() {
            let scope_vars = hashmap! {
                "item".to_string() => item.clone(),
                "index".to_string() => json!(index),
            };

            let result = self.sub_graph_executor.execute(
                sub_graph,
                pool,
                scope_vars,
                event_sender,
            ).await.map_err(|e| NodeError::ExecutionError(e.to_string()))?;

            // è·å–è½¬æ¢åçš„å€¼
            let value = result.get("value")
                .cloned()
                .unwrap_or(result);

            results.push(value);
        }

        Ok(json!(results))
    }

    /// Sort æ“ä½œ
    fn execute_sort(
        &self,
        config: &ListOperatorNodeConfig,
        input: &Value,
    ) -> Result<Value, NodeError> {
        let mut items = input.as_array()
            .ok_or_else(|| NodeError::TypeError("Input must be an array".to_string()))?
            .clone();

        let sort_key = config.sort_key.as_ref().unwrap();
        let sort_order = config.sort_order.unwrap_or(SortOrder::Asc);

        items.sort_by(|a, b| {
            let a_val = a.get(sort_key);
            let b_val = b.get(sort_key);

            let cmp = match (a_val, b_val) {
                (Some(Value::Number(a)), Some(Value::Number(b))) => {
                    a.as_f64().partial_cmp(&b.as_f64()).unwrap_or(std::cmp::Ordering::Equal)
                }
                (Some(Value::String(a)), Some(Value::String(b))) => {
                    a.cmp(b)
                }
                _ => std::cmp::Ordering::Equal,
            };

            match sort_order {
                SortOrder::Asc => cmp,
                SortOrder::Desc => cmp.reverse(),
            }
        });

        Ok(json!(items))
    }

    /// Slice æ“ä½œ
    fn execute_slice(
        &self,
        config: &ListOperatorNodeConfig,
        input: &Value,
    ) -> Result<Value, NodeError> {
        let items = input.as_array()
            .ok_or_else(|| NodeError::TypeError("Input must be an array".to_string()))?;

        let start = config.start.unwrap_or(0);
        let end = config.end.unwrap_or(items.len());

        let sliced: Vec<_> = items.iter()
            .skip(start)
            .take(end.saturating_sub(start))
            .cloned()
            .collect();

        Ok(json!(sliced))
    }

    /// First æ“ä½œ
    fn execute_first(&self, input: &Value) -> Result<Value, NodeError> {
        let items = input.as_array()
            .ok_or_else(|| NodeError::TypeError("Input must be an array".to_string()))?;

        Ok(items.first().cloned().unwrap_or(Value::Null))
    }

    /// Last æ“ä½œ
    fn execute_last(&self, input: &Value) -> Result<Value, NodeError> {
        let items = input.as_array()
            .ok_or_else(|| NodeError::TypeError("Input must be an array".to_string()))?;

        Ok(items.last().cloned().unwrap_or(Value::Null))
    }

    /// Flatten æ“ä½œ
    fn execute_flatten(&self, input: &Value) -> Result<Value, NodeError> {
        let items = input.as_array()
            .ok_or_else(|| NodeError::TypeError("Input must be an array".to_string()))?;

        let mut flattened = Vec::new();
        for item in items {
            if let Some(arr) = item.as_array() {
                flattened.extend(arr.iter().cloned());
            } else {
                flattened.push(item.clone());
            }
        }

        Ok(json!(flattened))
    }

    /// Unique æ“ä½œ
    fn execute_unique(&self, input: &Value) -> Result<Value, NodeError> {
        let items = input.as_array()
            .ok_or_else(|| NodeError::TypeError("Input must be an array".to_string()))?;

        let mut seen = std::collections::HashSet::new();
        let mut unique = Vec::new();

        for item in items {
            let key = serde_json::to_string(item).unwrap_or_default();
            if seen.insert(key) {
                unique.push(item.clone());
            }
        }

        Ok(json!(unique))
    }

    /// Reverse æ“ä½œ
    fn execute_reverse(&self, input: &Value) -> Result<Value, NodeError> {
        let items = input.as_array()
            .ok_or_else(|| NodeError::TypeError("Input must be an array".to_string()))?;

        let reversed: Vec<_> = items.iter().rev().cloned().collect();
        Ok(json!(reversed))
    }

    /// Concat æ“ä½œ
    async fn execute_concat(
        &self,
        config: &ListOperatorNodeConfig,
        input: &Value,
        pool: &Arc<RwLock<VariablePool>>,
    ) -> Result<Value, NodeError> {
        let items1 = input.as_array()
            .ok_or_else(|| NodeError::TypeError("Input must be an array".to_string()))?;

        let pool_read = pool.read().await;
        let second_selector = config.second_input_selector.as_ref().unwrap();
        let input2 = pool_read.get_value(second_selector)
            .ok_or_else(|| NodeError::VariableNotFound(second_selector.clone()))?;
        drop(pool_read);

        let items2 = input2.as_array()
            .ok_or_else(|| NodeError::TypeError("Second input must be an array".to_string()))?;

        let mut concatenated = items1.clone();
        concatenated.extend(items2.iter().cloned());

        Ok(json!(concatenated))
    }

    /// Reduce æ“ä½œ
    async fn execute_reduce(
        &self,
        config: &ListOperatorNodeConfig,
        input: &Value,
        pool: &Arc<RwLock<VariablePool>>,
        event_sender: &EventSender,
    ) -> Result<Value, NodeError> {
        let items = input.as_array()
            .ok_or_else(|| NodeError::TypeError("Input must be an array".to_string()))?;

        let sub_graph = config.sub_graph.as_ref().unwrap();
        let mut accumulator = config.initial_value.clone().unwrap_or(Value::Null);

        for (index, item) in items.iter().enumerate() {
            let scope_vars = hashmap! {
                "item".to_string() => item.clone(),
                "index".to_string() => json!(index),
                "accumulator".to_string() => accumulator.clone(),
            };

            let result = self.sub_graph_executor.execute(
                sub_graph,
                pool,
                scope_vars,
                event_sender,
            ).await.map_err(|e| NodeError::ExecutionError(e.to_string()))?;

            accumulator = result.get("value")
                .cloned()
                .unwrap_or(result);
        }

        Ok(accumulator)
    }

    /// Length æ“ä½œ
    fn execute_length(&self, input: &Value) -> Result<Value, NodeError> {
        let items = input.as_array()
            .ok_or_else(|| NodeError::TypeError("Input must be an array".to_string()))?;

        Ok(json!(items.len()))
    }
}
```

---

## 6. ä½œç”¨åŸŸç®¡ç†

### 6.1 ä½œç”¨åŸŸå±‚çº§

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å…¨å±€ä½œç”¨åŸŸ (Global Scope)                                   â”‚
â”‚  â€¢ ç³»ç»Ÿå˜é‡ (sys.query, sys.files)                          â”‚
â”‚  â€¢ ç”¨æˆ·è¾“å…¥ (input.*)                                       â”‚
â”‚  â€¢ å¯¹è¯å˜é‡ (conversation.*)                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  å·¥ä½œæµä½œç”¨åŸŸ (Workflow Scope)                          â”‚â”‚
â”‚  â”‚  â€¢ èŠ‚ç‚¹è¾“å‡º (node_id.output)                            â”‚â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚â”‚
â”‚  â”‚  â”‚  å­å›¾ä½œç”¨åŸŸ (Sub-graph Scope)                       â”‚â”‚â”‚
â”‚  â”‚  â”‚  â€¢ è¿­ä»£å˜é‡ (item, index)                           â”‚â”‚â”‚
â”‚  â”‚  â”‚  â€¢ å¾ªç¯å˜é‡ (loop.counter)                          â”‚â”‚â”‚
â”‚  â”‚  â”‚  â€¢ ç´¯åŠ å™¨ (accumulator)                             â”‚â”‚â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚â”‚â”‚
â”‚  â”‚  â”‚  â”‚  åµŒå¥—å­å›¾ä½œç”¨åŸŸ (Nested Sub-graph Scope)        â”‚â”‚â”‚â”‚
â”‚  â”‚  â”‚  â”‚  â€¢ å¯ä»¥è®¿é—®æ‰€æœ‰çˆ¶çº§ä½œç”¨åŸŸ                        â”‚â”‚â”‚â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚â”‚â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.2 VariablePool ä½œç”¨åŸŸå®ç°

```rust
/// å˜é‡æ± ï¼ˆæ”¯æŒä½œç”¨åŸŸï¼‰
pub struct VariablePool {
    /// èŠ‚ç‚¹è¾“å‡º
    node_outputs: DashMap<String, Value>,

    /// ç³»ç»Ÿå˜é‡
    system_vars: HashMap<String, Value>,

    /// å¯¹è¯å˜é‡
    conversation_vars: DashMap<String, Value>,

    /// ä½œç”¨åŸŸæ ˆ
    scope_stack: Vec<Scope>,
}

/// ä½œç”¨åŸŸ
#[derive(Debug, Clone)]
pub struct Scope {
    /// ä½œç”¨åŸŸ ID
    pub id: String,

    /// ä½œç”¨åŸŸå˜é‡
    pub variables: HashMap<String, Value>,

    /// çˆ¶ä½œç”¨åŸŸ IDï¼ˆç”¨äºåµŒå¥—ï¼‰
    pub parent_id: Option<String>,
}

impl VariablePool {
    /// è¿›å…¥æ–°ä½œç”¨åŸŸ
    pub fn push_scope(&mut self, scope_id: String, variables: HashMap<String, Value>) {
        let parent_id = self.scope_stack.last().map(|s| s.id.clone());

        self.scope_stack.push(Scope {
            id: scope_id,
            variables,
            parent_id,
        });
    }

    /// é€€å‡ºå½“å‰ä½œç”¨åŸŸ
    pub fn pop_scope(&mut self) -> Option<Scope> {
        self.scope_stack.pop()
    }

    /// è·å–å˜é‡å€¼ï¼ˆæ”¯æŒä½œç”¨åŸŸé“¾æŸ¥æ‰¾ï¼‰
    pub fn get_value(&self, selector: &str) -> Option<Value> {
        // 1. å…ˆåœ¨å½“å‰ä½œç”¨åŸŸæŸ¥æ‰¾
        if let Some(value) = self.get_from_current_scope(selector) {
            return Some(value);
        }

        // 2. åœ¨ä½œç”¨åŸŸé“¾ä¸­å‘ä¸ŠæŸ¥æ‰¾
        for scope in self.scope_stack.iter().rev() {
            if let Some(value) = scope.variables.get(selector) {
                return Some(value.clone());
            }
        }

        // 3. åœ¨èŠ‚ç‚¹è¾“å‡ºä¸­æŸ¥æ‰¾
        if let Some(value) = self.get_from_node_outputs(selector) {
            return Some(value);
        }

        // 4. åœ¨ç³»ç»Ÿå˜é‡ä¸­æŸ¥æ‰¾
        if let Some(value) = self.system_vars.get(selector) {
            return Some(value.clone());
        }

        None
    }

    /// ä»å½“å‰ä½œç”¨åŸŸè·å–
    fn get_from_current_scope(&self, selector: &str) -> Option<Value> {
        if let Some(scope) = self.scope_stack.last() {
            // ç›´æ¥å˜é‡å
            if let Some(value) = scope.variables.get(selector) {
                return Some(value.clone());
            }

            // ç‚¹å·åˆ†éš”çš„è·¯å¾„
            let parts: Vec<&str> = selector.split('.').collect();
            if let Some(value) = scope.variables.get(parts[0]) {
                return self.resolve_path(value, &parts[1..]);
            }
        }
        None
    }

    /// ä»èŠ‚ç‚¹è¾“å‡ºè·å–
    fn get_from_node_outputs(&self, selector: &str) -> Option<Value> {
        let parts: Vec<&str> = selector.split('.').collect();
        if parts.is_empty() {
            return None;
        }

        let node_id = parts[0];
        if let Some(output) = self.node_outputs.get(node_id) {
            if parts.len() == 1 {
                return Some(output.clone());
            }
            return self.resolve_path(&output, &parts[1..]);
        }

        None
    }

    /// è§£æè·¯å¾„
    fn resolve_path(&self, value: &Value, path: &[&str]) -> Option<Value> {
        let mut current = value.clone();

        for part in path {
            current = match current {
                Value::Object(map) => map.get(*part)?.clone(),
                Value::Array(arr) => {
                    let index: usize = part.parse().ok()?;
                    arr.get(index)?.clone()
                }
                _ => return None,
            };
        }

        Some(current)
    }

    /// è®¾ç½®ä½œç”¨åŸŸå˜é‡
    pub fn set_scope_variable(&mut self, name: &str, value: Value) {
        if let Some(scope) = self.scope_stack.last_mut() {
            scope.variables.insert(name.to_string(), value);
        }
    }

    /// è·å–å½“å‰ä½œç”¨åŸŸæ·±åº¦
    pub fn scope_depth(&self) -> usize {
        self.scope_stack.len()
    }
}
```

### 6.3 ä½œç”¨åŸŸå˜é‡è®¿é—®è§„åˆ™

| å˜é‡ç±»å‹ | è®¿é—®æ–¹å¼ | ç¤ºä¾‹ |
|---------|---------|------|
| è¿­ä»£å˜é‡ | ç›´æ¥è®¿é—® | `item`, `index` |
| å¾ªç¯å˜é‡ | `loop.` å‰ç¼€ | `loop.counter` |
| ç´¯åŠ å™¨ | ç›´æ¥è®¿é—® | `accumulator` |
| èŠ‚ç‚¹è¾“å‡º | `node_id.` å‰ç¼€ | `llm_1.text` |
| ç³»ç»Ÿå˜é‡ | `sys.` å‰ç¼€ | `sys.query` |
| ç”¨æˆ·è¾“å…¥ | `input.` å‰ç¼€ | `input.name` |

---

## 7. å¹¶è¡Œæ‰§è¡Œ

### 7.1 å¹¶è¡Œç­–ç•¥

```rust
/// å¹¶è¡Œæ‰§è¡Œé…ç½®
pub struct ParallelConfig {
    /// æ˜¯å¦å¯ç”¨å¹¶è¡Œ
    pub enabled: bool,

    /// æœ€å¤§å¹¶å‘æ•°
    pub max_concurrency: usize,

    /// æ˜¯å¦ä¿æŒé¡ºåº
    pub preserve_order: bool,
}

impl Default for ParallelConfig {
    fn default() -> Self {
        Self {
            enabled: true,
            max_concurrency: 10,
            preserve_order: true,
        }
    }
}
```

### 7.2 å¹¶è¡Œæ‰§è¡Œå™¨

```rust
/// å¹¶è¡Œå­å›¾æ‰§è¡Œå™¨
pub struct ParallelSubGraphExecutor {
    executor: Arc<SubGraphExecutor>,
    config: ParallelConfig,
}

impl ParallelSubGraphExecutor {
    /// å¹¶è¡Œæ‰§è¡Œå¤šä¸ªå­å›¾
    pub async fn execute_all(
        &self,
        sub_graph: &SubGraphDefinition,
        items: &[Value],
        pool: &Arc<RwLock<VariablePool>>,
        event_sender: &EventSender,
    ) -> Result<Vec<Value>, SubGraphError> {
        use tokio::sync::Semaphore;

        let semaphore = Arc::new(Semaphore::new(self.config.max_concurrency));
        let mut tasks = Vec::with_capacity(items.len());

        for (index, item) in items.iter().enumerate() {
            let permit = semaphore.clone().acquire_owned().await.unwrap();
            let executor = self.executor.clone();
            let sub_graph = sub_graph.clone();
            let pool_clone = pool.clone();
            let event_sender_clone = event_sender.clone();
            let item_clone = item.clone();

            let task = tokio::spawn(async move {
                let scope_vars = hashmap! {
                    "item".to_string() => item_clone,
                    "index".to_string() => json!(index),
                };

                let result = executor.execute(
                    &sub_graph,
                    &pool_clone,
                    scope_vars,
                    &event_sender_clone,
                ).await;

                drop(permit);
                (index, result)
            });

            tasks.push(task);
        }

        // æ”¶é›†ç»“æœ
        let mut results = vec![Value::Null; items.len()];

        for task in tasks {
            let (index, result) = task.await
                .map_err(|e| SubGraphError::ExecutionFailed(e.to_string()))?;

            results[index] = result?;
        }

        Ok(results)
    }
}
```

### 7.3 å¹¶è¡Œå®‰å…¨æ³¨æ„äº‹é¡¹

```rust
// âš ï¸ å¹¶è¡Œæ‰§è¡Œæ—¶çš„æ³¨æ„äº‹é¡¹

// 1. å˜é‡æ± è®¿é—®éœ€è¦åŒæ­¥
// ä½¿ç”¨ Arc<RwLock<VariablePool>> ç¡®ä¿çº¿ç¨‹å®‰å…¨
let pool = Arc::new(RwLock::new(VariablePool::new()));

// 2. ä½œç”¨åŸŸéš”ç¦»
// æ¯ä¸ªå¹¶è¡Œä»»åŠ¡æœ‰ç‹¬ç«‹çš„ä½œç”¨åŸŸ
// ä¸ä¼šç›¸äº’å½±å“

// 3. ç»“æœé¡ºåº
// ä½¿ç”¨ç´¢å¼•ç¡®ä¿ç»“æœé¡ºåºä¸è¾“å…¥ä¸€è‡´
let mut results = vec![Value::Null; items.len()];
results[index] = result;  // æŒ‰ç´¢å¼•å­˜å‚¨

// 4. é”™è¯¯å¤„ç†
// ä¸€ä¸ªä»»åŠ¡å¤±è´¥ä¸åº”å½±å“å…¶ä»–ä»»åŠ¡
// æ”¶é›†æ‰€æœ‰é”™è¯¯åç»Ÿä¸€å¤„ç†
```

---

## 8. æµ‹è¯•ç­–ç•¥

### 8.1 å•å…ƒæµ‹è¯•

```rust
#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_iteration_sequential() {
        let executor = IterationNodeExecutor::new(create_test_registry());

        let config = json!({
            "input_selector": "input.items",
            "parallel": false,
            "sub_graph": {
                "nodes": [
                    {"id": "start", "type": "start", "data": {}},
                    {"id": "end", "type": "end", "data": {
                        "outputs": [{"name": "value", "variable_selector": "item"}]
                    }}
                ],
                "edges": [
                    {"id": "e1", "source": "start", "target": "end"}
                ]
            },
            "output_variable": "results"
        });

        let pool = create_test_pool(json!({
            "items": [1, 2, 3]
        }));

        let ctx = create_test_context("iteration_1", config);
        let result = executor.execute(&ctx, &pool, &create_test_sender()).await.unwrap();

        assert_eq!(result, NodeExecutionResult::Completed(json!({
            "results": [1, 2, 3]
        })));
    }

    #[tokio::test]
    async fn test_iteration_parallel() {
        let executor = IterationNodeExecutor::new(create_test_registry());

        let config = json!({
            "input_selector": "input.items",
            "parallel": true,
            "parallelism": 5,
            "sub_graph": {
                "nodes": [
                    {"id": "start", "type": "start", "data": {}},
                    {"id": "double", "type": "code", "data": {
                        "language": "javascript",
                        "code": "function main(inputs) { return { value: inputs.item * 2 }; }",
                        "inputs": {"item": "item"},
                        "output_variable": "result"
                    }},
                    {"id": "end", "type": "end", "data": {
                        "outputs": [{"name": "value", "variable_selector": "double.result.value"}]
                    }}
                ],
                "edges": [
                    {"id": "e1", "source": "start", "target": "double"},
                    {"id": "e2", "source": "double", "target": "end"}
                ]
            },
            "output_variable": "results"
        });

        let pool = create_test_pool(json!({
            "items": [1, 2, 3, 4, 5]
        }));

        let ctx = create_test_context("iteration_1", config);
        let result = executor.execute(&ctx, &pool, &create_test_sender()).await.unwrap();

        // éªŒè¯ç»“æœï¼ˆé¡ºåºåº”è¯¥ä¿æŒï¼‰
        if let NodeExecutionResult::Completed(output) = result {
            assert_eq!(output["results"], json!([2, 4, 6, 8, 10]));
        }
    }

    #[tokio::test]
    async fn test_loop_basic() {
        let executor = LoopNodeExecutor::new(create_test_registry());

        let config = json!({
            "condition": {
                "variable_selector": "loop.counter",
                "comparison_operator": "less_than",
                "value": 5
            },
            "max_iterations": 100,
            "initial_vars": {
                "counter": 0,
                "sum": 0
            },
            "sub_graph": {
                "nodes": [
                    {"id": "start", "type": "start", "data": {}},
                    {"id": "increment", "type": "code", "data": {
                        "language": "javascript",
                        "code": "function main(inputs) { return { counter: inputs.counter + 1, sum: inputs.sum + inputs.counter }; }",
                        "inputs": {"counter": "loop.counter", "sum": "loop.sum"},
                        "output_variable": "result"
                    }},
                    {"id": "end", "type": "end", "data": {
                        "outputs": [
                            {"name": "counter", "variable_selector": "increment.result.counter"},
                            {"name": "sum", "variable_selector": "increment.result.sum"}
                        ]
                    }}
                ],
                "edges": [
                    {"id": "e1", "source": "start", "target": "increment"},
                    {"id": "e2", "source": "increment", "target": "end"}
                ]
            },
            "output_variable": "loop_result"
        });

        let pool = create_test_pool(json!({}));
        let ctx = create_test_context("loop_1", config);
        let result = executor.execute(&ctx, &pool, &create_test_sender()).await.unwrap();

        if let NodeExecutionResult::Completed(output) = result {
            assert_eq!(output["loop_result"]["counter"], 5);
            assert_eq!(output["loop_result"]["sum"], 10);  // 0+1+2+3+4
            assert_eq!(output["_iterations"], 5);
        }
    }

    #[tokio::test]
    async fn test_list_operator_filter() {
        let executor = ListOperatorNodeExecutor::new(create_test_registry());

        let config = json!({
            "operation": "filter",
            "input_selector": "input.numbers",
            "sub_graph": {
                "nodes": [
                    {"id": "start", "type": "start", "data": {}},
                    {"id": "check", "type": "code", "data": {
                        "language": "javascript",
                        "code": "function main(inputs) { return { keep: inputs.item > 5 }; }",
                        "inputs": {"item": "item"},
                        "output_variable": "result"
                    }},
                    {"id": "end", "type": "end", "data": {
                        "outputs": [{"name": "keep", "variable_selector": "check.result.keep"}]
                    }}
                ],
                "edges": [
                    {"id": "e1", "source": "start", "target": "check"},
                    {"id": "e2", "source": "check", "target": "end"}
                ]
            },
            "output_variable": "filtered"
        });

        let pool = create_test_pool(json!({
            "numbers": [1, 3, 5, 7, 9, 2, 4, 6, 8, 10]
        }));

        let ctx = create_test_context("filter_1", config);
        let result = executor.execute(&ctx, &pool, &create_test_sender()).await.unwrap();

        if let NodeExecutionResult::Completed(output) = result {
            assert_eq!(output["filtered"], json!([7, 9, 6, 8, 10]));
        }
    }

    #[tokio::test]
    async fn test_list_operator_sort() {
        let executor = ListOperatorNodeExecutor::new(create_test_registry());

        let config = json!({
            "operation": "sort",
            "input_selector": "input.items",
            "sort_key": "price",
            "sort_order": "desc",
            "output_variable": "sorted"
        });

        let pool = create_test_pool(json!({
            "items": [
                {"name": "A", "price": 10},
                {"name": "B", "price": 30},
                {"name": "C", "price": 20}
            ]
        }));

        let ctx = create_test_context("sort_1", config);
        let result = executor.execute(&ctx, &pool, &create_test_sender()).await.unwrap();

        if let NodeExecutionResult::Completed(output) = result {
            let sorted = output["sorted"].as_array().unwrap();
            assert_eq!(sorted[0]["name"], "B");
            assert_eq!(sorted[1]["name"], "C");
            assert_eq!(sorted[2]["name"], "A");
        }
    }
}
```

### 8.2 é›†æˆæµ‹è¯•

```rust
#[tokio::test]
async fn test_nested_iteration() {
    // æµ‹è¯•åµŒå¥—è¿­ä»£ï¼ˆè¿­ä»£ä¸­åŒ…å«è¿­ä»£ï¼‰
    let dsl = r#"
    nodes:
      - id: start
        type: start
      - id: outer_iter
        type: iteration
        data:
          input_selector: "input.matrix"
          parallel: false
          sub_graph:
            nodes:
              - id: inner_start
                type: start
              - id: inner_iter
                type: iteration
                data:
                  input_selector: "item"
                  parallel: true
                  sub_graph:
                    nodes:
                      - id: double_start
                        type: start
                      - id: double
                        type: code
                        data:
                          language: javascript
                          code: "function main(inputs) { return { value: inputs.item * 2 }; }"
                          inputs:
                            item: "item"
                          output_variable: "result"
                      - id: double_end
                        type: end
                        data:
                          outputs:
                            - name: value
                              variable_selector: "double.result.value"
                    edges:
                      - source: double_start
                        target: double
                      - source: double
                        target: double_end
                  output_variable: "doubled_row"
              - id: inner_end
                type: end
                data:
                  outputs:
                    - name: row
                      variable_selector: "inner_iter.doubled_row"
            edges:
              - source: inner_start
                target: inner_iter
              - source: inner_iter
                target: inner_end
          output_variable: "doubled_matrix"
      - id: end
        type: end
    edges:
      - source: start
        target: outer_iter
      - source: outer_iter
        target: end
    "#;

    let inputs = json!({
        "matrix": [
            [1, 2, 3],
            [4, 5, 6],
            [7, 8, 9]
        ]
    });

    let result = execute_workflow(dsl, inputs).await.unwrap();

    assert_eq!(result["doubled_matrix"], json!([
        [2, 4, 6],
        [8, 10, 12],
        [14, 16, 18]
    ]));
}
```

---

## 9. èŠ‚ç‚¹æ³¨å†Œ

```rust
/// æ³¨å†Œæ‰€æœ‰å­å›¾èŠ‚ç‚¹
pub fn register_subgraph_nodes(registry: &mut NodeRegistry) {
    let node_registry = Arc::new(registry.clone());

    registry.register(
        "iteration",
        Box::new(IterationNodeExecutor::new(node_registry.clone()))
    );

    registry.register(
        "loop",
        Box::new(LoopNodeExecutor::new(node_registry.clone()))
    );

    registry.register(
        "list-operator",
        Box::new(ListOperatorNodeExecutor::new(node_registry.clone()))
    );
}
```

---

## å˜æ›´å†å²

| ç‰ˆæœ¬ | æ—¥æœŸ | ä½œè€… | å˜æ›´è¯´æ˜ |
|------|------|------|---------|
| v1.0 | 2026-02-09 | Claude | åˆå§‹ç‰ˆæœ¬ |

---

**æ–‡æ¡£ç»“æŸ**
