# Checkpoint é€‰æ‹©æ€§æŒä¹…åŒ–è®¾è®¡æ–‡æ¡£

## 1. æ¦‚è¿°

æœ¬æ–‡æ¡£å®šä¹‰ xworkflow çš„**é€‰æ‹©æ€§æ£€æŸ¥ç‚¹**æœºåˆ¶ï¼Œä½¿ AI å·¥ä½œæµèƒ½å¤Ÿåœ¨é«˜æˆæœ¬èŠ‚ç‚¹ï¼ˆagentã€human-inputï¼‰å®Œæˆåä¿å­˜çŠ¶æ€ï¼Œåœ¨æ•…éšœåä»æ£€æŸ¥ç‚¹æ¢å¤ï¼Œä»¥åŠåœ¨äººå·¥å®¡æ‰¹èŠ‚ç‚¹æš‚åœ/æ¢å¤ã€‚

### è®¾è®¡çº¦æŸ

xworkflow çš„åŸå§‹å‡è®¾æ˜¯"çŸ­æ—¶è¿è¡Œã€ä¸åšæŒä¹…åŒ–ã€çº¯å†…å­˜"ã€‚AI æ—¶ä»£å¼•å…¥äº†æ–°éœ€æ±‚ï¼š

| ä¼ ç»Ÿå·¥ä½œæµ | AI å·¥ä½œæµ |
|-----------|----------|
| æ¯«ç§’çº§æ‰§è¡Œ | agent èŠ‚ç‚¹å¯èƒ½è·‘æ•°åˆ†é’Ÿ |
| å¤±è´¥é‡è·‘æˆæœ¬â‰ˆ0 | agent å¤±è´¥é‡è·‘èŠ±é’±+ç»“æœä¸åŒ |
| æ— äººå·¥ä»‹å…¥ | human-input ç­‰å¾…æ•°å°æ—¶ |
| ç¡®å®šæ€§ | LLM è¾“å‡ºä¸å¯å¤ç° |

ä½† xworkflow ä¸åº”å˜æˆ Temporal/Cadenceï¼š

| Temporal æ¨¡å¼ | æœ¬è®¾è®¡ |
|--------------|--------|
| æ¯æ­¥å†™æ•°æ®åº“ | ä»…åœ¨å…³é”®èŠ‚ç‚¹å­˜æ£€æŸ¥ç‚¹ |
| å¼ºä¾èµ– PostgreSQL | `CheckpointStore` traitï¼ŒåµŒå…¥æ–¹è‡ªå®šä¹‰ |
| æ¯ä¸ª activity åºåˆ—åŒ–å¼€é”€ | ç»å¤§å¤šæ•°èŠ‚ç‚¹é›¶å¼€é”€ |
| è¿ç»´å¤æ‚ | ä¸é…ç½® store æ—¶è¡Œä¸ºå®Œå…¨ä¸å˜ |

éµå¾ªé¡¹ç›®ä¸‰å¤§åŸåˆ™ï¼š**Security > Performance > Obviousness**ã€‚

### å·²æœ‰åŸºç¡€è®¾æ–½

| ç»„ä»¶ | ç°çŠ¶ | å¯¹æ£€æŸ¥ç‚¹çš„æ„ä¹‰ |
|------|------|---------------|
| `VariablePool` ä½¿ç”¨ `im::HashMap` | Copy-on-Write | `.snapshot()` å·²å­˜åœ¨ï¼Œé›¶æ‹·è´å¿«ç…§å¤©ç„¶æ”¯æŒ |
| `WorkflowNodeExecutionStatus::Paused` | æšä¸¾å·²å®šä¹‰ä½†æœªä½¿ç”¨ | å¯ç›´æ¥ç”¨äºæš‚åœè¯­ä¹‰ |
| `Command::Pause` | æšä¸¾å·²å®šä¹‰ | å¤–éƒ¨æš‚åœæŒ‡ä»¤é€šé“å·²å­˜åœ¨ |
| `Graph.node_states` | `HashMap<String, EdgeTraversalState>` | å¯ç›´æ¥åºåˆ—åŒ– |
| `EventEmitter` | äº‹ä»¶æ€»çº¿ | å¯å‘å°„æ£€æŸ¥ç‚¹äº‹ä»¶ |

---

## 2. CheckpointStore Trait

**æ–‡ä»¶**: æ–°å»º `src/core/checkpoint.rs`

### 2.1 æ ¸å¿ƒ Trait

```rust
use serde::{Deserialize, Serialize};
use std::collections::HashMap;

/// æ£€æŸ¥ç‚¹å­˜å‚¨æ¥å£ â€” åµŒå…¥æ–¹å®ç°ï¼Œå†³å®šå­˜åœ¨å“ªé‡Œ
///
/// å¯èƒ½çš„å®ç°ï¼š
/// - `MemoryCheckpointStore` â€” å†…å­˜ä¸­ï¼ˆæµ‹è¯•/å¼€å‘ï¼‰
/// - `FileCheckpointStore` â€” æ–‡ä»¶ç³»ç»Ÿ
/// - `SqliteCheckpointStore` â€” SQLiteï¼ˆè½»é‡æŒä¹…åŒ–ï¼‰
/// - `RedisCheckpointStore` â€” Redisï¼ˆåˆ†å¸ƒå¼åœºæ™¯ï¼‰
/// - ç”¨æˆ·è‡ªå®šä¹‰
#[async_trait]
pub trait CheckpointStore: Send + Sync {
    /// ä¿å­˜æ£€æŸ¥ç‚¹ï¼ˆè¦†ç›–åŒä¸€ workflow_id çš„æ—§æ£€æŸ¥ç‚¹ï¼‰
    async fn save(
        &self,
        workflow_id: &str,
        checkpoint: &Checkpoint,
    ) -> Result<(), CheckpointError>;

    /// åŠ è½½æœ€è¿‘çš„æ£€æŸ¥ç‚¹ï¼ˆä¸å­˜åœ¨æ—¶è¿”å› Noneï¼‰
    async fn load(
        &self,
        workflow_id: &str,
    ) -> Result<Option<Checkpoint>, CheckpointError>;

    /// åˆ é™¤æ£€æŸ¥ç‚¹ï¼ˆworkflow å®Œæˆåæ¸…ç†ï¼‰
    async fn delete(
        &self,
        workflow_id: &str,
    ) -> Result<(), CheckpointError>;
}
```

### 2.2 Checkpoint æ•°æ®ç»“æ„

```rust
/// æ£€æŸ¥ç‚¹ â€” å·¥ä½œæµåœ¨æŸä¸ªèŠ‚ç‚¹å®Œæˆåçš„å®Œæ•´å¿«ç…§
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct Checkpoint {
    // === æ ‡è¯† ===
    /// å·¥ä½œæµå®ä¾‹ ID
    pub workflow_id: String,
    /// åŸå§‹æ‰§è¡Œ IDï¼ˆç”¨äºå®¡è®¡è¿½è¸ªå…³è”ï¼‰
    pub execution_id: String,
    /// æ£€æŸ¥ç‚¹åˆ›å»ºæ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
    pub created_at: i64,

    // === DAG çŠ¶æ€ ===
    /// æœ€åå®Œæˆçš„èŠ‚ç‚¹ IDï¼ˆæ£€æŸ¥ç‚¹è§¦å‘ç‚¹ï¼‰
    pub completed_node_id: String,
    /// æ¯ä¸ªèŠ‚ç‚¹çš„éå†çŠ¶æ€ï¼ˆPending/Taken/Skipped/Cancelledï¼‰
    pub node_states: HashMap<String, SerializableEdgeState>,
    /// æ¯æ¡è¾¹çš„éå†çŠ¶æ€
    pub edge_states: HashMap<String, SerializableEdgeState>,
    /// ä¸‹ä¸€æ­¥å¾…æ‰§è¡Œçš„èŠ‚ç‚¹ ID åˆ—è¡¨
    pub ready_queue: Vec<String>,
    /// å‰é©±èŠ‚ç‚¹æ˜ å°„
    pub ready_predecessor: HashMap<String, String>,

    // === å˜é‡çŠ¶æ€ ===
    /// VariablePool å¿«ç…§ï¼ˆé€šè¿‡ pool.snapshot() è·å–ï¼‰
    pub variables: HashMap<String, serde_json::Value>,

    // === æ‰§è¡Œå…ƒæ•°æ® ===
    /// å·²æ‰§è¡Œæ­¥æ•°
    pub step_count: i32,
    /// å¼‚å¸¸è®¡æ•°
    pub exceptions_count: i32,
    /// å·²æ”¶é›†çš„æœ€ç»ˆè¾“å‡º
    pub final_outputs: HashMap<String, serde_json::Value>,
    /// å·²æ¶ˆè€—æ—¶é—´ï¼ˆç§’ï¼‰
    pub elapsed_secs: u64,

    // === èµ„æºæ¶ˆè€—ï¼ˆæ¢å¤ ResourceGovernor çŠ¶æ€ï¼‰ ===
    /// æ£€æŸ¥ç‚¹å‰ç´¯è®¡çš„èµ„æºæ¶ˆè€—ï¼ˆä»… security feature ä¸‹æœ‰æ„ä¹‰ï¼‰
    pub consumed_resources: Option<ConsumedResources>,
}

/// ç´¯è®¡èµ„æºæ¶ˆè€—æ‘˜è¦ â€” æ¢å¤æ—¶é€šçŸ¥ ResourceGovernor
#[derive(Serialize, Deserialize, Debug, Clone, Default)]
pub struct ConsumedResources {
    /// ç´¯è®¡ LLM prompt tokens
    pub total_prompt_tokens: i64,
    /// ç´¯è®¡ LLM completion tokens
    pub total_completion_tokens: i64,
    /// ç´¯è®¡ LLM è°ƒç”¨æˆæœ¬
    pub total_llm_cost: f64,
    /// ç´¯è®¡ MCP tool è°ƒç”¨æ¬¡æ•°
    pub total_tool_calls: i64,
}

/// å¯åºåˆ—åŒ–çš„ EdgeTraversalState
#[derive(Serialize, Deserialize, Debug, Clone, Copy, PartialEq, Eq)]
#[serde(rename_all = "snake_case")]
pub enum SerializableEdgeState {
    Pending,
    Taken,
    Skipped,
    Cancelled,
}

impl From<EdgeTraversalState> for SerializableEdgeState {
    fn from(state: EdgeTraversalState) -> Self {
        match state {
            EdgeTraversalState::Pending => Self::Pending,
            EdgeTraversalState::Taken => Self::Taken,
            EdgeTraversalState::Skipped => Self::Skipped,
            EdgeTraversalState::Cancelled => Self::Cancelled,
        }
    }
}

impl From<SerializableEdgeState> for EdgeTraversalState {
    fn from(state: SerializableEdgeState) -> Self {
        match state {
            SerializableEdgeState::Pending => Self::Pending,
            SerializableEdgeState::Taken => Self::Taken,
            SerializableEdgeState::Skipped => Self::Skipped,
            SerializableEdgeState::Cancelled => Self::Cancelled,
        }
    }
}
```

### 2.3 CheckpointError

```rust
#[derive(Debug, thiserror::Error)]
pub enum CheckpointError {
    #[error("Serialization error: {0}")]
    SerializationError(String),
    #[error("Storage error: {0}")]
    StorageError(String),
    #[error("Checkpoint not found for workflow: {0}")]
    NotFound(String),
    #[error("Checkpoint corrupted: {0}")]
    Corrupted(String),
}
```

### è®¾è®¡å†³ç­–

| å†³ç­– | ç†ç”± |
|------|------|
| `variables` ä¸º `HashMap<String, Value>` è€Œé `HashMap<String, Segment>` | Segment ä¸­ Stream ç±»å‹ä¸å¯åºåˆ—åŒ–ï¼›è½¬ä¸º Value åæ‰€æœ‰ç±»å‹éƒ½å¯å®‰å…¨åºåˆ—åŒ– |
| ä»…å­˜æœ€è¿‘ä¸€ä¸ªæ£€æŸ¥ç‚¹ï¼ˆè¦†ç›–å†™ï¼‰ | å·¥ä½œæµæ˜¯ DAG ä¸å¯å›é€€ï¼Œåªéœ€æœ€æ–°å¿«ç…§ï¼›å‡å°‘å­˜å‚¨ |
| `ready_queue` + `ready_predecessor` ä¿å­˜ | æ¢å¤æ—¶ç›´æ¥ä»é˜Ÿåˆ—ç»§ç»­ï¼Œæ— éœ€é‡æ–°éå† DAG |
| `elapsed_secs` ä¿å­˜ | æ¢å¤åç»§ç»­è®¡æ—¶ï¼Œé˜²æ­¢è¶…æ—¶é€»è¾‘å¤±æ•ˆ |
| Node/Edge states ä½¿ç”¨è‡ªå®šä¹‰å¯åºåˆ—åŒ–ç±»å‹ | `EdgeTraversalState` åŸå§‹ç±»å‹æœª derive Serialize |
| `execution_id` ä¿å­˜ | å®¡è®¡è¿½è¸ªéœ€è¦å…³è”åŒä¸€æ¬¡æ‰§è¡Œçš„ checkpoint å‰åé˜¶æ®µ |
| `consumed_resources` ä¿å­˜ | æ¢å¤åé€šçŸ¥ `ResourceGovernor`ï¼Œé˜²æ­¢é…é¢è®¡ç®—åå·® |

### RuntimeContext ä¸å­˜å‚¨

`WorkflowContext` / `RuntimeGroup` çš„å†…å®¹**ä¸çº³å…¥æ£€æŸ¥ç‚¹**ã€‚åŸå› ï¼š

| RuntimeContext å­—æ®µ | ä¸å­˜çš„ç†ç”± |
|------|------|
| `time_provider: Arc<dyn TimeProvider>` | trait object ä¸å¯åºåˆ—åŒ–ï¼›æ¢å¤æ—¶é‡æ–°åˆ›å»º |
| `id_generator: Arc<dyn IdGenerator>` | trait object ä¸å¯åºåˆ—åŒ–ï¼›æ¢å¤æ—¶é‡æ–°åˆ›å»º |
| `event_tx: mpsc::Sender` | æ´»è·ƒ channel ä¸å¯åºåˆ—åŒ–ï¼›æ¢å¤æ—¶æ–°å»º |
| `node_executor_registry` | å†…å« `Box<dyn NodeExecutor>` ä¸å¯åºåˆ—åŒ– |
| `llm_provider_registry` | å†…å« `Arc<dyn LlmProvider>` ä¸å¯åºåˆ—åŒ– |
| `http_client_provider` | è¿æ¥æ± ï¼Œä¸å¯åºåˆ—åŒ– |
| `credential_provider` | `Arc<dyn>` ä¸å¯åºåˆ—åŒ– |
| `resource_governor` | `Arc<dyn>` ä¸å¯åºåˆ—åŒ–ï¼›å·²æ¶ˆè€—é‡é€šè¿‡ `consumed_resources` æ¢å¤ |
| `audit_logger` | `Arc<dyn>` ä¸å¯åºåˆ—åŒ– |
| `sandbox_pool` | `Arc<dyn>` ä¸å¯åºåˆ—åŒ– |
| `template_functions` | `Arc<dyn>` ä¸å¯åºåˆ—åŒ– |
| `strict_template`, `group_id`, `security_policy`, `quota` | é…ç½®ç±»å­—æ®µï¼Œç”±è°ƒç”¨æ–¹é€šè¿‡ builder é‡æ–°æä¾› |

**èŒè´£åˆ†ç¦»**ï¼šæ£€æŸ¥ç‚¹è´Ÿè´£æ¢å¤å¼•æ“æ‰§è¡Œè¿›åº¦ï¼ˆDAG çŠ¶æ€ + å˜é‡ï¼‰ï¼Œè°ƒç”¨æ–¹è´Ÿè´£é‡å»ºè¿è¡Œç¯å¢ƒï¼ˆProviderã€å‡­è¯ã€å®‰å…¨ç­–ç•¥ï¼‰ã€‚æ¢å¤æ—¶è°ƒç”¨æ–¹ä½¿ç”¨ç›¸åŒçš„ `WorkflowRunnerBuilder` é…ç½®åˆ›å»ºæ–°çš„ runnerã€‚

---

## 3. VariablePool åºåˆ—åŒ–

### 3.1 ç°æœ‰èƒ½åŠ›

`VariablePool::snapshot()` å·²å­˜åœ¨ï¼ˆ`src/core/variable_pool.rs:1532`ï¼‰ï¼š

```rust
pub fn snapshot(&self) -> HashMap<String, Segment> {
    self.variables
        .iter()
        .map(|(k, v)| (k.to_string(), v.clone()))
        .collect()
}
```

`Segment` å·²å®ç° `Serialize` å’Œ `Deserialize`ã€‚

### 3.2 Stream å¤„ç†

`Segment::Stream` åŒ…å«å¼‚æ­¥çŠ¶æ€ï¼ˆ`RwLock<StreamState>`ï¼‰ï¼Œä¸å¯ç›´æ¥åºåˆ—åŒ–ã€‚

æ£€æŸ¥ç‚¹æ—¶çš„å¤„ç†ç­–ç•¥ï¼š

```rust
/// å°† VariablePool å¿«ç…§è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„ HashMap<String, Value>
pub fn snapshot_for_checkpoint(pool: &VariablePool) -> HashMap<String, Value> {
    pool.snapshot()
        .into_iter()
        .filter_map(|(k, seg)| {
            match &seg {
                // Stream ç±»å‹ï¼šå°è¯•æå–å·²å®Œæˆçš„å€¼ï¼Œæœªå®Œæˆåˆ™è·³è¿‡
                Segment::Stream(stream) => {
                    match stream.try_snapshot() {
                        Some(completed) => Some((k, completed.to_value())),
                        None => None,  // æµå°šæœªå®Œæˆï¼Œä¸çº³å…¥æ£€æŸ¥ç‚¹
                    }
                }
                // å…¶ä»–ç±»å‹ï¼šç›´æ¥è½¬ä¸º Value
                other => {
                    Some((k, serde_json::to_value(other).unwrap_or(Value::Null)))
                }
            }
        })
        .collect()
}
```

### 3.3 ä»æ£€æŸ¥ç‚¹æ¢å¤ VariablePool

```rust
/// ä»æ£€æŸ¥ç‚¹æ•°æ®é‡å»º VariablePool
pub fn restore_from_checkpoint(
    variables: &HashMap<String, Value>,
) -> VariablePool {
    let mut pool = VariablePool::new();
    for (key, value) in variables {
        // ä» pool key è§£æ Selector
        if let Some(selector) = Selector::from_pool_key(key) {
            pool.set(&selector, Segment::from_value(value));
        }
    }
    pool
}
```

---

## 4. Dispatcher é›†æˆ

### 4.1 WorkflowDispatcher æ–°å¢å­—æ®µ

**æ–‡ä»¶**: `src/core/dispatcher.rs`

```rust
pub struct WorkflowDispatcher<G: DebugGate = NoopGate, H: DebugHook = NoopHook> {
    // ... ç°æœ‰å­—æ®µ ...
    graph: Arc<RwLock<Graph>>,
    variable_pool: Arc<RwLock<VariablePool>>,
    registry: Arc<NodeExecutorRegistry>,
    // ...

    /// å¯é€‰çš„æ£€æŸ¥ç‚¹å­˜å‚¨ï¼ˆNone = æ— æ£€æŸ¥ç‚¹ï¼Œé›¶å¼€é”€ï¼‰
    checkpoint_store: Option<Arc<dyn CheckpointStore>>,
    /// Workflow IDï¼ˆæ£€æŸ¥ç‚¹çš„ keyï¼‰
    workflow_id: String,
}
```

### 4.2 æ£€æŸ¥ç‚¹ç­–ç•¥ â€” å“ªäº›èŠ‚ç‚¹è§¦å‘

```rust
impl<G: DebugGate, H: DebugHook> WorkflowDispatcher<G, H> {
    /// åˆ¤æ–­èŠ‚ç‚¹æ‰§è¡Œå®Œæˆåæ˜¯å¦éœ€è¦ä¿å­˜æ£€æŸ¥ç‚¹
    fn should_checkpoint_after(&self, node_type: &str, node_config: &Value) -> bool {
        // æ²¡æœ‰ store â†’ æ°¸è¿œä¸å­˜
        if self.checkpoint_store.is_none() {
            return false;
        }

        match node_type {
            // agent èŠ‚ç‚¹ï¼šæ€»æ˜¯å­˜ï¼ˆé«˜æˆæœ¬ã€éç¡®å®šæ€§ï¼‰
            "agent" => true,
            // human-input èŠ‚ç‚¹ï¼šæ‰§è¡Œå‰å­˜ï¼ˆéœ€è¦æš‚åœç­‰å¾…ï¼‰
            // æ³¨æ„ï¼šhuman-input æ˜¯ before ç­–ç•¥ï¼Œåœ¨ should_checkpoint_before ä¸­å¤„ç†
            "human-input" => false,
            // å…¶ä»–èŠ‚ç‚¹ï¼šçœ‹é…ç½®ä¸­æ˜¯å¦æ˜¾å¼å£°æ˜
            _ => node_config.get("checkpoint")
                .and_then(|v| v.as_bool())
                .unwrap_or(false),
        }
    }

    /// åˆ¤æ–­èŠ‚ç‚¹æ‰§è¡Œå‰æ˜¯å¦éœ€è¦ä¿å­˜æ£€æŸ¥ç‚¹
    fn should_checkpoint_before(&self, node_type: &str) -> bool {
        if self.checkpoint_store.is_none() {
            return false;
        }
        // human-input èŠ‚ç‚¹æ‰§è¡Œå‰å­˜æ£€æŸ¥ç‚¹ï¼ˆå› ä¸ºå³å°†æš‚åœï¼‰
        node_type == "human-input"
    }
}
```

### 4.3 run() æ–¹æ³•ä¿®æ”¹

å¯¹ `run()` çš„æ”¹åŠ¨æœ€å°åŒ–ã€‚åœ¨ç°æœ‰å¾ªç¯ä¸­æ’å…¥ä¸¤å¤„æ£€æŸ¥ç‚¹é€»è¾‘ï¼š

```rust
pub async fn run(&mut self) -> WorkflowResult<HashMap<String, Value>> {
    self.event_emitter.emit(GraphEngineEvent::GraphRunStarted).await;
    self.emit_before_workflow_hooks().await?;

    // ===== æ–°å¢ï¼šå°è¯•ä»æ£€æŸ¥ç‚¹æ¢å¤ =====
    let (mut ready, mut ready_predecessor, mut step_count, start_time) =
        if let Some(resumed) = self.try_resume_from_checkpoint().await? {
            resumed
        } else {
            // æ­£å¸¸å¯åŠ¨
            let root_id = self.graph.read().root_node_id().to_string();
            (vec![root_id], HashMap::new(), 0i32, self.context.time_provider.now_timestamp())
        };

    let mut join_set: JoinSet<NodeExecOutcome> = JoinSet::new();
    let mut running: HashMap<String, AbortHandle> = HashMap::new();
    let mut gather_wait_started: HashMap<String, i64> = HashMap::new();

    let (max_steps, max_exec_time) = self.effective_limits();
    // ... ç°æœ‰ max_concurrency é€»è¾‘ ...

    loop {
        // ... ç°æœ‰ gather timeout é€»è¾‘ ...
        // ... ç°æœ‰ debug_index é€»è¾‘ ...
        // ... ç°æœ‰ parallel spawn é€»è¾‘ ...
        // ... ç°æœ‰ join_next é€»è¾‘ ...

        match run_result {
            Ok(result) => {
                // ... ç°æœ‰ handle_node_success é€»è¾‘ ...

                // ===== æ–°å¢ï¼šèŠ‚ç‚¹æˆåŠŸåæ£€æŸ¥ç‚¹ =====
                if self.should_checkpoint_after(
                    &outcome.info.node_type, &outcome.info.node_config
                ) {
                    self.save_checkpoint(
                        &outcome.node_id,
                        &ready,
                        &ready_predecessor,
                        step_count,
                        start_time,
                    ).await?;
                }
            }
            Err(e) => {
                // ... ç°æœ‰é”™è¯¯å¤„ç† ...
            }
        }
    }

    // ===== æ–°å¢ï¼šå®Œæˆååˆ é™¤æ£€æŸ¥ç‚¹ =====
    self.delete_checkpoint().await;

    // ... ç°æœ‰ event emission ...
    self.emit_after_workflow_hooks().await?;
    Ok(self.final_outputs.clone())
}
```

### 4.4 æ£€æŸ¥ç‚¹ä¿å­˜ä¸æ¢å¤

```rust
impl<G: DebugGate, H: DebugHook> WorkflowDispatcher<G, H> {
    /// ä¿å­˜æ£€æŸ¥ç‚¹
    async fn save_checkpoint(
        &self,
        completed_node_id: &str,
        ready: &[String],
        ready_predecessor: &HashMap<String, String>,
        step_count: i32,
        start_time: i64,
    ) -> WorkflowResult<()> {
        let Some(store) = &self.checkpoint_store else {
            return Ok(());
        };

        let pool = self.variable_pool.read();
        let graph = self.graph.read();

        let checkpoint = Checkpoint {
            workflow_id: self.workflow_id.clone(),
            created_at: self.context.time_provider.now_millis(),

            completed_node_id: completed_node_id.to_string(),
            node_states: graph.node_states.iter()
                .map(|(k, v)| (k.clone(), (*v).into()))
                .collect(),
            edge_states: graph.edge_states.iter()
                .map(|(k, v)| (k.clone(), (*v).into()))
                .collect(),
            ready_queue: ready.to_vec(),
            ready_predecessor: ready_predecessor.clone(),

            variables: snapshot_for_checkpoint(&pool),

            step_count,
            exceptions_count: self.exceptions_count,
            final_outputs: self.final_outputs.clone(),
            elapsed_secs: self.context.time_provider.elapsed_secs(start_time),
        };

        store.save(&self.workflow_id, &checkpoint).await
            .map_err(|e| WorkflowError::InternalError(
                format!("Checkpoint save failed: {}", e)
            ))?;

        self.event_emitter.emit(GraphEngineEvent::CheckpointSaved {
            node_id: completed_node_id.to_string(),
        }).await;

        Ok(())
    }

    /// å°è¯•ä»æ£€æŸ¥ç‚¹æ¢å¤
    async fn try_resume_from_checkpoint(
        &mut self,
    ) -> WorkflowResult<Option<(Vec<String>, HashMap<String, String>, i32, i64)>> {
        let Some(store) = &self.checkpoint_store else {
            return Ok(None);
        };

        let Some(cp) = store.load(&self.workflow_id).await
            .map_err(|e| WorkflowError::InternalError(
                format!("Checkpoint load failed: {}", e)
            ))?
        else {
            return Ok(None);
        };

        // æ¢å¤ Graph çŠ¶æ€
        {
            let mut graph = self.graph.write();
            for (node_id, state) in &cp.node_states {
                graph.set_node_state(node_id, (*state).into());
            }
            for (edge_id, state) in &cp.edge_states {
                graph.set_edge_state(edge_id, (*state).into());
            }
        }

        // æ¢å¤ VariablePool
        {
            let mut pool = self.variable_pool.write();
            *pool = restore_from_checkpoint(&cp.variables);
        }

        // æ¢å¤æ‰§è¡Œå…ƒæ•°æ®
        self.exceptions_count = cp.exceptions_count;
        self.final_outputs = cp.final_outputs;

        // è°ƒæ•´ start_time ä»¥è¡¥å¿å·²æ¶ˆè€—æ—¶é—´
        let adjusted_start = self.context.time_provider.now_timestamp()
            - cp.elapsed_secs as i64;

        self.event_emitter.emit(GraphEngineEvent::CheckpointResumed {
            node_id: cp.completed_node_id.clone(),
        }).await;

        Ok(Some((
            cp.ready_queue,
            cp.ready_predecessor,
            cp.step_count,
            adjusted_start,
        )))
    }

    /// åˆ é™¤æ£€æŸ¥ç‚¹ï¼ˆworkflow æ­£å¸¸å®Œæˆåè°ƒç”¨ï¼‰
    async fn delete_checkpoint(&self) {
        if let Some(store) = &self.checkpoint_store {
            let _ = store.delete(&self.workflow_id).await;
        }
    }
}
```

---

## 5. WorkflowHandle æš‚åœ/æ¢å¤

### 5.1 ExecutionStatus æ‰©å±•

**æ–‡ä»¶**: `src/scheduler.rs`

```rust
#[derive(Debug, Clone)]
pub enum ExecutionStatus {
    Running,
    Completed(HashMap<String, Value>),
    Failed(String),
    FailedWithRecovery {
        original_error: String,
        recovered_outputs: HashMap<String, Value>,
    },
    /// å·¥ä½œæµåœ¨ human-input èŠ‚ç‚¹æš‚åœï¼Œç­‰å¾…å¤–éƒ¨è¾“å…¥
    Paused {
        /// æš‚åœåœ¨å“ªä¸ªèŠ‚ç‚¹
        node_id: String,
        /// èŠ‚ç‚¹æ ‡é¢˜ï¼ˆç”¨äº UI å±•ç¤ºï¼‰
        node_title: String,
        /// æç¤ºä¿¡æ¯ï¼ˆå‘Šè¯‰ç”¨æˆ·éœ€è¦æä¾›ä»€ä¹ˆï¼‰
        prompt: String,
    },
}
```

### 5.2 WorkflowHandle æ–°å¢æ–¹æ³•

```rust
impl WorkflowHandle {
    // ... ç°æœ‰ status(), wait(), events() ...

    /// ç­‰å¾…ç›´åˆ° workflow åˆ°è¾¾ç»ˆæ€æˆ–æš‚åœ
    pub async fn wait_or_paused(&self) -> ExecutionStatus {
        let mut rx = self.status_rx.clone();
        loop {
            let status = rx.borrow().clone();
            match status {
                ExecutionStatus::Running => {
                    if rx.changed().await.is_err() {
                        return rx.borrow().clone();
                    }
                }
                // Paused ä¹Ÿæ˜¯å¯ä»¥ç­‰åˆ°çš„çŠ¶æ€
                _ => return status,
            }
        }
    }

    /// å‘æš‚åœçš„ workflow æäº¤ human inputï¼Œæ¢å¤æ‰§è¡Œ
    pub async fn resume_with_input(
        &self,
        input: HashMap<String, Value>,
    ) -> Result<(), WorkflowError> {
        self.command_tx.send(Command::ResumeWithInput { input })
            .await
            .map_err(|_| WorkflowError::InternalError(
                "Workflow already terminated".to_string()
            ))
    }
}
```

### 5.3 Command æ‰©å±•

**æ–‡ä»¶**: `src/core/dispatcher.rs`

```rust
#[derive(Debug, Clone)]
pub enum Command {
    Abort { reason: Option<String> },
    Pause,
    UpdateVariables { variables: HashMap<String, Value> },
    /// æ¢å¤æš‚åœçš„ workflowï¼Œæ³¨å…¥ human input
    ResumeWithInput { input: HashMap<String, Value> },
    /// å®‰å…¨åœæ­¢ï¼šä¿å­˜æ£€æŸ¥ç‚¹åç»ˆæ­¢
    SafeStop,
}
```

### 5.4 ExecutionStatus æ‰©å±•

```rust
#[derive(Debug, Clone)]
pub enum ExecutionStatus {
    Running,
    Completed(HashMap<String, Value>),
    Failed(String),
    FailedWithRecovery { original_error: String, recovered_outputs: HashMap<String, Value> },
    Paused { node_id: String, node_title: String, prompt: String },
    /// å®‰å…¨åœæ­¢å®Œæˆ â€” æ‰€æœ‰è¿›è¡Œä¸­çš„å·¥ä½œå·²ä¿å­˜æ£€æŸ¥ç‚¹
    SafeStopped {
        /// æœ€åå®Œæˆçš„èŠ‚ç‚¹ ID
        last_completed_node: Option<String>,
        /// è¢«ä¸­æ–­çš„èŠ‚ç‚¹ ID åˆ—è¡¨ï¼ˆæ­£åœ¨æ‰§è¡Œä½†æœªå®Œæˆï¼‰
        interrupted_nodes: Vec<String>,
        /// æ£€æŸ¥ç‚¹ä¿å­˜æ˜¯å¦æˆåŠŸ
        checkpoint_saved: bool,
    },
}
```

### 5.5 SafeStopSignal â€” è·¨ workflow å¹¿æ’­

**æ–‡ä»¶**: `src/core/checkpoint.rs`

```rust
use tokio_util::sync::CancellationToken;

/// å®‰å…¨åœæ­¢ä¿¡å· â€” å¯åœ¨å¤šä¸ª workflow ä¹‹é—´å…±äº«
///
/// è°ƒç”¨ `trigger()` åï¼Œæ‰€æœ‰æŒæœ‰è¯¥ signal clone çš„ workflow
/// ä¼šåœ¨å½“å‰èŠ‚ç‚¹å®Œæˆåä¿å­˜æ£€æŸ¥ç‚¹å¹¶ç»ˆæ­¢ã€‚
#[derive(Clone)]
pub struct SafeStopSignal {
    token: CancellationToken,
    /// ç­‰å¾…æ­£åœ¨æ‰§è¡Œçš„èŠ‚ç‚¹å®Œæˆçš„è¶…æ—¶æ—¶é—´
    timeout: Arc<AtomicU64>,
}

impl SafeStopSignal {
    pub fn new() -> Self {
        Self {
            token: CancellationToken::new(),
            timeout: Arc::new(AtomicU64::new(30)),
        }
    }

    /// è§¦å‘å®‰å…¨åœæ­¢
    ///
    /// `timeout_secs`: ç­‰å¾…æ­£åœ¨æ‰§è¡Œçš„èŠ‚ç‚¹å®Œæˆçš„æœ€é•¿æ—¶é—´ã€‚
    /// è¶…æ—¶åä»æœªå®Œæˆçš„èŠ‚ç‚¹ä¼šè¢«ä¸­æ–­ï¼ˆç»“æœä¸¢å¤±ï¼Œä»ä¸Šä¸€ä¸ªæ£€æŸ¥ç‚¹æ¢å¤ï¼‰ã€‚
    pub fn trigger(&self, timeout_secs: u64) {
        self.timeout.store(timeout_secs, Ordering::Relaxed);
        self.token.cancel();
    }

    /// æ˜¯å¦å·²è§¦å‘
    pub fn is_triggered(&self) -> bool {
        self.token.is_cancelled()
    }

    /// è·å– CancellationToken ç”¨äº select!
    pub fn cancelled(&self) -> tokio_util::sync::WaitForCancellationFuture<'_> {
        self.token.cancelled()
    }

    /// è·å–è¶…æ—¶ç§’æ•°
    pub fn timeout_secs(&self) -> u64 {
        self.timeout.load(Ordering::Relaxed)
    }
}
```

### 5.6 WorkflowRunnerBuilder æ–°å¢æ–¹æ³•

```rust
impl WorkflowRunnerBuilder {
    // ... ç°æœ‰æ–¹æ³• ...

    /// è®¾ç½®æ£€æŸ¥ç‚¹å­˜å‚¨ï¼ˆå¯é€‰ï¼‰
    pub fn checkpoint_store(mut self, store: Arc<dyn CheckpointStore>) -> Self {
        self.checkpoint_store = Some(store);
        self
    }

    /// è®¾ç½® Workflow IDï¼ˆæ£€æŸ¥ç‚¹çš„ keyï¼›ä¸è®¾åˆ™è‡ªåŠ¨ç”Ÿæˆï¼‰
    pub fn workflow_id(mut self, id: String) -> Self {
        self.workflow_id = Some(id);
        self
    }

    /// è®¾ç½®å®‰å…¨åœæ­¢ä¿¡å·ï¼ˆå¯é€‰ï¼Œå¤šä¸ª workflow å¯å…±äº«åŒä¸€ä¸ª signalï¼‰
    pub fn safe_stop_signal(mut self, signal: SafeStopSignal) -> Self {
        self.safe_stop_signal = Some(signal);
        self
    }
}
```

---

## 6. Human-Input èŠ‚ç‚¹

### 6.1 Executor

**æ–‡ä»¶**: æ–°å»º `src/nodes/human_input.rs`

```rust
/// Human-Input èŠ‚ç‚¹ â€” æš‚åœå·¥ä½œæµç­‰å¾…äººå·¥è¾“å…¥
pub struct HumanInputExecutor;

#[async_trait]
impl NodeExecutor for HumanInputExecutor {
    async fn execute(
        &self,
        node_id: &str,
        config: &Value,
        variable_pool: &VariablePool,
        context: &RuntimeContext,
    ) -> Result<NodeRunResult, NodeError> {
        let cfg: HumanInputNodeData = serde_json::from_value(config.clone())
            .map_err(|e| NodeError::ConfigError(e.to_string()))?;

        // æ¸²æŸ“æç¤ºä¿¡æ¯æ¨¡æ¿
        let prompt = render_template(&cfg.prompt, variable_pool)?;

        // è¿”å› Paused çŠ¶æ€ â€” Dispatcher ä¼šå°†æ­¤çŠ¶æ€å¹¿æ’­åˆ° WorkflowHandle
        Ok(NodeRunResult {
            status: WorkflowNodeExecutionStatus::Paused,
            metadata: {
                let mut m = HashMap::new();
                m.insert("prompt".to_string(), Value::String(prompt));
                m.insert("node_title".to_string(), Value::String(cfg.title.clone()));
                m
            },
            ..Default::default()
        })
    }
}
```

### 6.2 Dispatcher å¤„ç† Paused çŠ¶æ€

åœ¨ `handle_node_success` æ–¹æ³•ä¸­ï¼š

```rust
async fn handle_node_success(
    &mut self,
    exec_id: &str,
    node_id: &str,
    info: &NodeInfo,
    result: NodeRunResult,
    ready: &mut Vec<String>,
) -> WorkflowResult<Vec<String>> {
    // ... ç°æœ‰é€»è¾‘ ...

    // æ–°å¢ï¼šå¤„ç† Paused çŠ¶æ€
    if result.status == WorkflowNodeExecutionStatus::Paused {
        let prompt = result.metadata.get("prompt")
            .and_then(|v| v.as_str())
            .unwrap_or("")
            .to_string();
        let title = result.metadata.get("node_title")
            .and_then(|v| v.as_str())
            .unwrap_or("")
            .to_string();

        // ä¿å­˜æ£€æŸ¥ç‚¹ï¼ˆæš‚åœå‰ï¼‰
        self.save_checkpoint(node_id, ready, &HashMap::new(), step_count, start_time).await?;

        // å¹¿æ’­ Paused çŠ¶æ€
        self.status_tx.send_replace(ExecutionStatus::Paused {
            node_id: node_id.to_string(),
            node_title: title,
            prompt,
        });

        // ç­‰å¾… ResumeWithInput å‘½ä»¤
        let input = self.wait_for_resume().await?;

        // æ³¨å…¥ human input åˆ° variable pool
        {
            let mut pool = self.variable_pool.write();
            for (key, value) in input {
                let selector = Selector::new(node_id, &key);
                pool.set(&selector, Segment::from_value(&value));
            }
        }

        // å¹¿æ’­æ¢å¤ä¸º Running
        self.status_tx.send_replace(ExecutionStatus::Running);

        // ç»§ç»­æ­£å¸¸æµç¨‹ï¼šæ¨è¿›ä¸‹æ¸¸è¾¹
    }

    // ... ç°æœ‰çš„ advance_graph_after_success ...
}
```

### 6.3 DSL ç¤ºä¾‹

```yaml
- id: approval
  data:
    type: human-input
    title: "Manager Approval"
    prompt: |
      Agent analysis: {{research.text}}

      Approve this action?
    variables:
      - name: approved
        type: boolean
        required: true
      - name: comments
        type: string

# åç»­èŠ‚ç‚¹ä½¿ç”¨ human input
- id: check_approval
  data:
    type: if-else
    conditions:
      - id: approved
        variable_selector: [approval, approved]
        comparison: "eq"
        value: true
```

---

## 7. è°ƒç”¨æ–¹ä½¿ç”¨ç¤ºä¾‹

### 7.1 åŸºæœ¬ç”¨æ³•ï¼ˆæ— æ£€æŸ¥ç‚¹ï¼‰

```rust
// è¡Œä¸ºä¸ç°åœ¨å®Œå…¨ä¸€è‡´ï¼Œé›¶å¼€é”€
let handle = WorkflowRunner::builder(schema)
    .user_inputs(inputs)
    .build()
    .run()
    .await?;

let status = handle.wait().await;
```

### 7.2 å¸¦æ£€æŸ¥ç‚¹

```rust
let store = Arc::new(SqliteCheckpointStore::new("checkpoints.db"));
let workflow_id = "order-12345".to_string();

let handle = WorkflowRunner::builder(schema)
    .user_inputs(inputs)
    .checkpoint_store(store.clone())
    .workflow_id(workflow_id.clone())
    .build()
    .run()
    .await?;

let status = handle.wait().await;
// agent èŠ‚ç‚¹å®Œæˆåè‡ªåŠ¨å­˜äº†æ£€æŸ¥ç‚¹
// workflow æ­£å¸¸å®Œæˆåè‡ªåŠ¨åˆ äº†æ£€æŸ¥ç‚¹
```

### 7.3 æ•…éšœæ¢å¤

```rust
// ç¬¬ä¸€æ¬¡è¿è¡Œï¼Œcrash åœ¨ send_email èŠ‚ç‚¹
let handle = WorkflowRunner::builder(schema.clone())
    .checkpoint_store(store.clone())
    .workflow_id("order-12345".to_string())
    .build()
    .run()
    .await?;
// handle.wait() â†’ Failed("send_email timeout")
// ä½† agent èŠ‚ç‚¹çš„ç»“æœå·²ä¿å­˜åœ¨æ£€æŸ¥ç‚¹ä¸­

// ç¬¬äºŒæ¬¡è¿è¡Œï¼šè‡ªåŠ¨ä» agent ä¹‹åæ¢å¤ï¼Œè·³è¿‡å·²å®Œæˆçš„ agent
let handle = WorkflowRunner::builder(schema)
    .checkpoint_store(store.clone())
    .workflow_id("order-12345".to_string())  // åŒä¸€ä¸ª workflow_id
    .build()
    .run()
    .await?;
let status = handle.wait().await;
// è¿™æ¬¡ä» agent åçš„èŠ‚ç‚¹å¼€å§‹ï¼Œä¸é‡è·‘ agentï¼Œçœäº† $3
```

### 7.4 Human-in-the-loop

```rust
let handle = WorkflowRunner::builder(schema)
    .checkpoint_store(store.clone())
    .workflow_id("ticket-67890".to_string())
    .build()
    .run()
    .await?;

loop {
    match handle.wait_or_paused().await {
        ExecutionStatus::Paused { node_id, prompt, .. } => {
            println!("Approval needed: {}", prompt);
            // å±•ç¤ºç»™ç”¨æˆ·...ç”¨æˆ·æ“ä½œå...
            let input = HashMap::from([
                ("approved".to_string(), Value::Bool(true)),
                ("comments".to_string(), Value::String("LGTM".into())),
            ]);
            handle.resume_with_input(input).await?;
        }
        ExecutionStatus::Completed(outputs) => {
            println!("Done: {:?}", outputs);
            break;
        }
        ExecutionStatus::Failed(err) => {
            eprintln!("Error: {}", err);
            break;
        }
        _ => {}
    }
}
```

### 7.5 å®‰å…¨åœæ­¢ï¼ˆå•ä¸ª workflowï¼‰

```rust
let handle = WorkflowRunner::builder(schema)
    .checkpoint_store(store.clone())
    .workflow_id("order-123".to_string())
    .build()
    .run()
    .await?;

// æŸä¸ªæ—¶åˆ»éœ€è¦åœæ­¢ï¼ˆæ¯”å¦‚æ”¶åˆ° SIGTERMï¼‰
handle.safe_stop().await;

match handle.wait().await {
    ExecutionStatus::SafeStopped { checkpoint_saved, .. } => {
        assert!(checkpoint_saved);
        // ä¸‹æ¬¡ç”¨åŒä¸€ä¸ª workflow_id å¯åŠ¨å³å¯æ¢å¤
    }
    _ => {}
}
```

### 7.6 å®‰å…¨åœæ­¢ï¼ˆæ‰€æœ‰ workflowï¼Œä¼˜é›…å…³é—­ï¼‰

```rust
let shutdown_signal = SafeStopSignal::new();

// å¤šä¸ª workflow å…±äº«åŒä¸€ä¸ª signal
let handle1 = WorkflowRunner::builder(schema1)
    .checkpoint_store(store.clone())
    .workflow_id("order-001".to_string())
    .safe_stop_signal(shutdown_signal.clone())
    .build()
    .run()
    .await?;

let handle2 = WorkflowRunner::builder(schema2)
    .checkpoint_store(store.clone())
    .workflow_id("order-002".to_string())
    .safe_stop_signal(shutdown_signal.clone())
    .build()
    .run()
    .await?;

// ç›‘å¬ç³»ç»Ÿä¿¡å·
tokio::spawn(async move {
    tokio::signal::ctrl_c().await.unwrap();
    println!("Received SIGINT, safe stopping all workflows...");
    // ç»™æ­£åœ¨æ‰§è¡Œçš„èŠ‚ç‚¹ 30 ç§’å®Œæˆ
    shutdown_signal.trigger(30);
});

// ç­‰å¾…æ‰€æœ‰ workflow åœæ­¢
let status1 = handle1.wait().await;
let status2 = handle2.wait().await;
// ä¸¤ä¸ªéƒ½æ˜¯ SafeStoppedï¼Œä¸‹æ¬¡å¯åŠ¨è¿›ç¨‹åå¯æ¢å¤
```

---

## 8. å®‰å…¨åœæ­¢ï¼ˆSafe Stopï¼‰

### 8.1 æ¦‚è¿°

å®‰å…¨åœæ­¢å…è®¸åœ¨ä¸ä¸¢å¤±å·¥ä½œè¿›åº¦çš„æƒ…å†µä¸‹ç»ˆæ­¢å·¥ä½œæµæ‰§è¡Œã€‚å…¸å‹åœºæ™¯ï¼š
- æœåŠ¡éƒ¨ç½²æ›´æ–°ï¼ˆæ»šåŠ¨å‘å¸ƒï¼‰
- æ”¶åˆ° SIGTERM/SIGINT ä¿¡å·
- èµ„æºä¸è¶³éœ€è¦è…¾å‡º
- è¿ç»´äººå‘˜æ‰‹åŠ¨å¹²é¢„

### 8.2 æ‰§è¡Œæµç¨‹

```
æ­£å¸¸æ‰§è¡Œä¸­ï¼š
  ready: [node_C, node_D]    â† ç­‰å¾…æ‰§è¡Œ
  running: {node_A, node_B}  â† æ­£åœ¨æ‰§è¡Œ

æ”¶åˆ° SafeStop ä¿¡å·ï¼š

  1. åœæ­¢è°ƒåº¦ â† ready é˜Ÿåˆ—å†»ç»“ï¼Œä¸å†æ´¾å‘æ–°èŠ‚ç‚¹
     ready: [node_C, node_D]  (å†»ç»“)
     running: {node_A, node_B} (ç»§ç»­)

  2. ç­‰å¾…æ­£åœ¨æ‰§è¡Œçš„èŠ‚ç‚¹å®Œæˆï¼ˆå¸¦è¶…æ—¶ï¼‰
     â”Œâ”€ node_A å®Œæˆ â†’ æ­£å¸¸å¤„ç†ç»“æœã€æ›´æ–°å˜é‡
     â”‚  â†’ ready å¯èƒ½å˜ä¸º [node_C, node_D, node_E]ï¼ˆä½†ä¸æ´¾å‘ï¼‰
     â”‚
     â””â”€ node_B è¶…æ—¶æœªå®Œæˆ â†’ å¼ºåˆ¶ä¸­æ–­
        â†’ node_B çš„ç»“æœä¸¢å¤±ï¼ˆä¸‹æ¬¡ä»ä¸Šä¸€ä¸ªæ£€æŸ¥ç‚¹æ¢å¤æ—¶é‡è·‘ï¼‰

  3. ä¿å­˜æ£€æŸ¥ç‚¹
     checkpoint = {
       node_states: {A: Taken, B: Pending, C: Pending, D: Pending},
       ready_queue: [node_B, node_C, node_D, node_E],  // B å›åˆ° ready
       variables: åŒ…å« A çš„è¾“å‡ºï¼Œä¸å« B çš„è¾“å‡º,
     }

  4. å¹¿æ’­ SafeStopped çŠ¶æ€ â†’ WorkflowHandle æ”¶åˆ°ç»ˆæ€
```

### 8.3 Dispatcher å®ç°

**æ–‡ä»¶**: `src/core/dispatcher.rs`

#### run() å¾ªç¯ä¸­æ–°å¢å®‰å…¨åœæ­¢æ£€æµ‹

```rust
pub async fn run(&mut self) -> WorkflowResult<HashMap<String, Value>> {
    // ... ç°æœ‰åˆå§‹åŒ– ...

    loop {
        // ===== æ–°å¢ï¼šå®‰å…¨åœæ­¢æ£€æµ‹ =====
        if self.is_safe_stop_triggered() {
            let outcome = self.execute_safe_stop(
                &mut ready,
                &mut ready_predecessor,
                &mut running,
                &mut join_set,
                step_count,
                start_time,
            ).await?;
            return outcome;
        }

        // ... ç°æœ‰ gather timeout é€»è¾‘ ...
        // ... ç°æœ‰ dispatch/join é€»è¾‘ ...
    }
}
```

#### å®‰å…¨åœæ­¢æ£€æµ‹

```rust
fn is_safe_stop_triggered(&self) -> bool {
    // æ–¹å¼ 1: SafeStopSignalï¼ˆè·¨ workflow å¹¿æ’­ï¼‰
    if let Some(signal) = &self.safe_stop_signal {
        if signal.is_triggered() {
            return true;
        }
    }

    // æ–¹å¼ 2: Command é€šé“ï¼ˆå• workflowï¼‰
    if let Some(rx) = &self.command_rx {
        if let Ok(Command::SafeStop) = rx.try_recv() {
            return true;
        }
    }

    false
}
```

#### å®‰å…¨åœæ­¢æ‰§è¡Œ

```rust
async fn execute_safe_stop(
    &mut self,
    ready: &mut Vec<String>,
    ready_predecessor: &mut HashMap<String, String>,
    running: &mut HashMap<String, AbortHandle>,
    join_set: &mut JoinSet<NodeExecOutcome>,
    step_count: i32,
    start_time: i64,
) -> WorkflowResult<HashMap<String, Value>> {
    let timeout_secs = self.safe_stop_signal
        .as_ref()
        .map(|s| s.timeout_secs())
        .unwrap_or(30);

    let mut interrupted_nodes = Vec::new();
    let mut last_completed = None;

    // 1. ç­‰å¾…æ­£åœ¨æ‰§è¡Œçš„èŠ‚ç‚¹å®Œæˆï¼ˆå¸¦è¶…æ—¶ï¼‰
    if !join_set.is_empty() {
        let deadline = tokio::time::Instant::now()
            + tokio::time::Duration::from_secs(timeout_secs);

        loop {
            tokio::select! {
                joined = join_set.join_next() => {
                    let Some(joined) = joined else { break };

                    match joined {
                        Ok(outcome) => {
                            running.remove(&outcome.node_id);
                            last_completed = Some(outcome.node_id.clone());

                            // æ­£å¸¸å¤„ç†å®Œæˆçš„èŠ‚ç‚¹
                            match outcome.result {
                                Ok(result) => {
                                    let _ = self.handle_node_success(
                                        &outcome.exec_id,
                                        &outcome.node_id,
                                        &outcome.info,
                                        result,
                                        ready,
                                    ).await;
                                }
                                Err(_) => {
                                    // èŠ‚ç‚¹å¤±è´¥ â†’ ä¸å½±å“å®‰å…¨åœæ­¢ï¼Œç»§ç»­ç­‰å…¶ä»–èŠ‚ç‚¹
                                }
                            }
                        }
                        Err(join_error) => {
                            if !join_error.is_cancelled() {
                                // JoinError â†’ è®°å½•ä½†ä¸é˜»æ­¢å®‰å…¨åœæ­¢
                            }
                        }
                    }

                    if running.is_empty() {
                        break;
                    }
                }
                _ = tokio::time::sleep_until(deadline) => {
                    // è¶…æ—¶ï¼šä¸­æ–­æ‰€æœ‰æœªå®Œæˆçš„èŠ‚ç‚¹
                    for (node_id, handle) in running.drain() {
                        handle.abort();
                        interrupted_nodes.push(node_id.clone());
                        // è¢«ä¸­æ–­çš„èŠ‚ç‚¹å›åˆ° ready é˜Ÿåˆ—ï¼ˆä¸‹æ¬¡æ¢å¤æ—¶é‡è·‘ï¼‰
                        ready.push(node_id);
                    }
                    join_set.abort_all();
                    // æ¶ˆè€—æ‰€æœ‰ JoinError
                    while join_set.join_next().await.is_some() {}
                    break;
                }
            }
        }
    }

    // 2. ä¿å­˜æ£€æŸ¥ç‚¹
    let checkpoint_saved = if self.checkpoint_store.is_some() {
        let result = self.save_checkpoint(
            last_completed.as_deref().unwrap_or("safe_stop"),
            ready,
            ready_predecessor,
            step_count,
            start_time,
        ).await;
        result.is_ok()
    } else {
        false
    };

    // 3. å‘å°„äº‹ä»¶
    self.event_emitter.emit(GraphEngineEvent::WorkflowSafeStopped {
        interrupted_nodes: interrupted_nodes.clone(),
        checkpoint_saved,
    }).await;

    // 4. è¿”å› SafeStopped çŠ¶æ€ï¼ˆé€šè¿‡ Err ä¼ é€’ï¼Œè®©è°ƒç”¨æ–¹å¤„ç†ï¼‰
    Err(WorkflowError::SafeStopped {
        last_completed_node: last_completed,
        interrupted_nodes,
        checkpoint_saved,
    })
}
```

### 8.4 WorkflowHandle æ–¹æ³•

```rust
impl WorkflowHandle {
    // ... ç°æœ‰æ–¹æ³• ...

    /// è¯·æ±‚å®‰å…¨åœæ­¢ï¼ˆå•ä¸ª workflowï¼‰
    pub async fn safe_stop(&self) -> Result<(), WorkflowError> {
        self.command_tx.send(Command::SafeStop)
            .await
            .map_err(|_| WorkflowError::InternalError(
                "Workflow already terminated".to_string()
            ))
    }
}
```

### 8.5 æ—  CheckpointStore æ—¶çš„è¡Œä¸º

| æœ‰ CheckpointStore | æ—  CheckpointStore |
|---|---|
| ç­‰å¾…èŠ‚ç‚¹å®Œæˆ â†’ ä¿å­˜æ£€æŸ¥ç‚¹ â†’ SafeStopped | ç­‰å¾…èŠ‚ç‚¹å®Œæˆ â†’ SafeStopped |
| ä¸‹æ¬¡å¯åŠ¨å¯æ¢å¤ | ä¸‹æ¬¡å¯åŠ¨ä»å¤´å¼€å§‹ |
| `checkpoint_saved: true` | `checkpoint_saved: false` |

æ—  CheckpointStore æ—¶å®‰å…¨åœæ­¢ä»ç„¶æœ‰æ„ä¹‰ï¼šç»™æ­£åœ¨æ‰§è¡Œçš„èŠ‚ç‚¹æ—¶é—´å®Œæˆï¼Œè€Œä¸æ˜¯ç›´æ¥ killã€‚

### 8.6 ä¸ç°æœ‰ Command::Abort çš„åŒºåˆ«

| | Abort | SafeStop |
|---|---|---|
| æ­£åœ¨æ‰§è¡Œçš„èŠ‚ç‚¹ | ç«‹å³ä¸­æ–­ | ç­‰å¾…å®Œæˆï¼ˆå¸¦è¶…æ—¶ï¼‰ |
| æ£€æŸ¥ç‚¹ | ä¸ä¿å­˜ | ä¿å­˜ |
| å¯æ¢å¤ | å¦ | æ˜¯ |
| è¿”å›çŠ¶æ€ | Failed | SafeStopped |
| è¯­ä¹‰ | "å‡ºé”™äº†ï¼Œæ”¾å¼ƒ" | "éœ€è¦åœäº†ï¼Œä½†ä¿ç•™è¿›åº¦" |

---

## 9. å†…ç½® CheckpointStore å®ç°

å†…å­˜å’Œæ–‡ä»¶ä¸¤ç§ `CheckpointStore` ä½œä¸º**å†…ç½®å®ç°**ï¼Œéš `checkpoint` feature ä¸€èµ·ç¼–è¯‘ã€‚å…¶ä»–å­˜å‚¨åç«¯ï¼ˆRedisã€SQLiteã€S3 ç­‰ï¼‰é€šè¿‡**æ’ä»¶ç³»ç»Ÿ**æ‰©å±•ã€‚

```
å†…ç½®ï¼ˆcheckpoint featureï¼‰         æ’ä»¶æ‰©å±•ï¼ˆplugin-system featureï¼‰
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MemoryCheckpointStore â”‚         â”‚ RedisCheckpointStore     â”‚
â”‚ FileCheckpointStore   â”‚         â”‚ SqliteCheckpointStore    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚ S3CheckpointStore        â”‚
                                  â”‚ ç”¨æˆ·è‡ªå®šä¹‰...             â”‚
                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 9.1 MemoryCheckpointStoreï¼ˆå†…ç½® â€” æµ‹è¯•/å¼€å‘ï¼‰

```rust
/// å†…å­˜æ£€æŸ¥ç‚¹å­˜å‚¨ â€” è¿›ç¨‹é€€å‡ºå³ä¸¢å¤±
pub struct MemoryCheckpointStore {
    data: tokio::sync::RwLock<HashMap<String, Checkpoint>>,
}

#[async_trait]
impl CheckpointStore for MemoryCheckpointStore {
    async fn save(&self, workflow_id: &str, cp: &Checkpoint) -> Result<(), CheckpointError> {
        self.data.write().await.insert(workflow_id.to_string(), cp.clone());
        Ok(())
    }

    async fn load(&self, workflow_id: &str) -> Result<Option<Checkpoint>, CheckpointError> {
        Ok(self.data.read().await.get(workflow_id).cloned())
    }

    async fn delete(&self, workflow_id: &str) -> Result<(), CheckpointError> {
        self.data.write().await.remove(workflow_id);
        Ok(())
    }
}
```

### 9.2 FileCheckpointStoreï¼ˆå†…ç½® â€” è½»é‡æŒä¹…åŒ–ï¼‰

```rust
/// æ–‡ä»¶ç³»ç»Ÿæ£€æŸ¥ç‚¹å­˜å‚¨ â€” æ¯ä¸ª workflow ä¸€ä¸ª JSON æ–‡ä»¶
pub struct FileCheckpointStore {
    dir: PathBuf,
}

#[async_trait]
impl CheckpointStore for FileCheckpointStore {
    async fn save(&self, workflow_id: &str, cp: &Checkpoint) -> Result<(), CheckpointError> {
        let path = self.dir.join(format!("{}.checkpoint.json", workflow_id));
        let data = serde_json::to_vec(cp)
            .map_err(|e| CheckpointError::SerializationError(e.to_string()))?;
        tokio::fs::write(&path, &data).await
            .map_err(|e| CheckpointError::StorageError(e.to_string()))?;
        Ok(())
    }

    async fn load(&self, workflow_id: &str) -> Result<Option<Checkpoint>, CheckpointError> {
        let path = self.dir.join(format!("{}.checkpoint.json", workflow_id));
        match tokio::fs::read(&path).await {
            Ok(data) => {
                let cp = serde_json::from_slice(&data)
                    .map_err(|e| CheckpointError::Corrupted(e.to_string()))?;
                Ok(Some(cp))
            }
            Err(e) if e.kind() == std::io::ErrorKind::NotFound => Ok(None),
            Err(e) => Err(CheckpointError::StorageError(e.to_string())),
        }
    }

    async fn delete(&self, workflow_id: &str) -> Result<(), CheckpointError> {
        let path = self.dir.join(format!("{}.checkpoint.json", workflow_id));
        let _ = tokio::fs::remove_file(&path).await;
        Ok(())
    }
}
```

### 9.3 æ’ä»¶æ‰©å±•æ–¹å¼

ç¬¬ä¸‰æ–¹ `CheckpointStore` å®ç°é€šè¿‡**æ’ä»¶ç³»ç»Ÿæ³¨å†Œ**ï¼ˆBootstrap æˆ– Normal é˜¶æ®µå‡å¯ï¼‰ï¼š

```rust
pub struct RedisCheckpointPlugin {
    metadata: PluginMetadata,
    config: RedisConfig,
}

#[async_trait]
impl Plugin for RedisCheckpointPlugin {
    fn metadata(&self) -> &PluginMetadata {
        &self.metadata  // Bootstrap æˆ– Normal å‡å¯
    }

    async fn register(&self, ctx: &mut PluginContext) -> Result<(), PluginError> {
        let store = RedisCheckpointStore::connect(&self.config).await?;
        ctx.provide_service::<Arc<dyn CheckpointStore>>(Arc::new(store))?;
        Ok(())
    }
}
```

**ä¸ºä»€ä¹ˆä¸é™å®š Bootstrapï¼Ÿ** CheckpointStore ä»…åœ¨ `Dispatcher::run()` æ—¶æ¶ˆè´¹ï¼Œè€Œ `run()` åœ¨æ‰€æœ‰æ’ä»¶é˜¶æ®µï¼ˆBootstrap + Normalï¼‰å®Œæˆä¹‹åæ‰å¼€å§‹ã€‚æ²¡æœ‰å…¶ä»–æ’ä»¶åœ¨æ³¨å†ŒæœŸé—´ä¾èµ– CheckpointStoreï¼Œå› æ­¤æ— éœ€å¼ºåˆ¶æå‰æ³¨å†Œã€‚æ’ä»¶ä½œè€…å¯æ ¹æ®è‡ªèº«æƒ…å†µé€‰æ‹©é˜¶æ®µã€‚

`WorkflowRunnerBuilder` åœ¨æ‰€æœ‰æ’ä»¶é˜¶æ®µå®Œæˆåæ£€æŸ¥æ˜¯å¦æœ‰æ’ä»¶æä¾›çš„ `CheckpointStore`ï¼š

```rust
// scheduler.rs ä¸­ï¼Œæ‰€æœ‰æ’ä»¶æ³¨å†Œå®Œæˆå
if builder.checkpoint_store.is_none() {
    if let Some(store) = plugin_registry.query_service::<Arc<dyn CheckpointStore>>() {
        builder.checkpoint_store = Some(store);
    }
}
```

è¿™æ ·ç”¨æˆ·å¯ä»¥ï¼š
- **ç›´æ¥æ³¨å…¥**ï¼š`builder.checkpoint_store(Arc::new(FileCheckpointStore::new(...)))`
- **é€šè¿‡æ’ä»¶**ï¼šåŠ è½½ Redis/SQLite æ’ä»¶ï¼Œè‡ªåŠ¨æ³¨å†Œåˆ° builder

---

## 10. GraphEngineEvent æ‰©å±•

**æ–‡ä»¶**: `src/core/event_bus.rs`

```rust
pub enum GraphEngineEvent {
    // ... ç°æœ‰äº‹ä»¶ ...
    GraphRunStarted,
    GraphRunSucceeded { outputs },
    GraphRunPartialSucceeded { exceptions_count, outputs },
    GraphRunFailed { error },
    // ... èŠ‚ç‚¹äº‹ä»¶ ...

    /// æ£€æŸ¥ç‚¹å·²ä¿å­˜
    CheckpointSaved {
        node_id: String,
    },
    /// ä»æ£€æŸ¥ç‚¹æ¢å¤
    CheckpointResumed {
        node_id: String,
    },
    /// Workflow æš‚åœç­‰å¾…äººå·¥è¾“å…¥
    WorkflowPaused {
        node_id: String,
        prompt: String,
    },
    /// Workflow ä»æš‚åœæ¢å¤
    WorkflowResumed {
        node_id: String,
    },
    /// æ¢å¤æ—¶æ£€æµ‹åˆ°ç¯å¢ƒå˜åŒ–è­¦å‘Šï¼ˆNormal ç­–ç•¥ä¸‹ Warning çº§åˆ«ï¼‰
    ResumeWarning {
        diagnostic: String,
    },
    /// å®‰å…¨åœæ­¢å®Œæˆ
    WorkflowSafeStopped {
        interrupted_nodes: Vec<String>,
        checkpoint_saved: bool,
    },
}
```

---

## 11. Feature Gating

**æ–‡ä»¶**: `Cargo.toml`

```toml
[features]
default = [
    "security", "plugin-system",
    # "checkpoint",      # é»˜è®¤ä¸å¼€å¯
]

# æ£€æŸ¥ç‚¹æ”¯æŒ
checkpoint = []
```

æ‰€æœ‰æ£€æŸ¥ç‚¹ç›¸å…³ä»£ç ä½¿ç”¨ `#[cfg(feature = "checkpoint")]` é—¨æ§ï¼š

```rust
#[cfg(feature = "checkpoint")]
pub mod checkpoint;

// dispatcher.rs
#[cfg(feature = "checkpoint")]
checkpoint_store: Option<Arc<dyn CheckpointStore>>,

#[cfg(not(feature = "checkpoint"))]
// ä¸å­˜åœ¨ checkpoint_store å­—æ®µï¼Œé›¶å¼€é”€
```

ä¸å¼€å¯ `checkpoint` feature æ—¶ï¼š
- `WorkflowDispatcher` æ²¡æœ‰ `checkpoint_store` å­—æ®µ
- `run()` æ–¹æ³•ä¸­æ— ä»»ä½•æ£€æŸ¥ç‚¹é€»è¾‘
- ç¼–è¯‘åäºŒè¿›åˆ¶é›¶å¢é‡

---

## 12. Security ç›¸å…³

### 12.1 æ£€æŸ¥ç‚¹æ•°æ®å®‰å…¨

- **å˜é‡å¯èƒ½åŒ…å«æ•æ„Ÿä¿¡æ¯**ï¼ˆç”¨æˆ·è¾“å…¥ã€API å¯†é’¥ã€LLM è¾“å‡ºï¼‰
- `CheckpointStore` å®ç°æ–¹è´Ÿè´£åŠ å¯†å­˜å‚¨ï¼ˆåœ¨ trait doc ä¸­è¯´æ˜ï¼‰
- å†…ç½®çš„ `FileCheckpointStore` åº”åœ¨æ–‡æ¡£ä¸­è­¦å‘Šï¼šæ–‡ä»¶æœªåŠ å¯†

### 12.2 å®¡è®¡

æ£€æŸ¥ç‚¹æ“ä½œé€šè¿‡ `GraphEngineEvent` è®°å½•ï¼š
- `CheckpointSaved` â€” è°çš„ workflowã€åœ¨å“ªä¸ªèŠ‚ç‚¹ä¿å­˜
- `CheckpointResumed` â€” è°çš„ workflowã€ä»å“ªä¸ªèŠ‚ç‚¹æ¢å¤

### 12.3 æ£€æŸ¥ç‚¹æœ‰æ•ˆæ€§

æ¢å¤æ—¶éœ€éªŒè¯ï¼š
- Schema ç‰ˆæœ¬æ˜¯å¦åŒ¹é…ï¼ˆæ£€æŸ¥ç‚¹ä¸­ä¿å­˜çš„ workflow ç‰ˆæœ¬ä¸å½“å‰ schema ä¸€è‡´ï¼‰
- èŠ‚ç‚¹ ID æ˜¯å¦ä»å­˜åœ¨äºå½“å‰ DAG ä¸­
- ä¸åŒ¹é…æ—¶æ‹’ç»æ¢å¤ï¼Œè¿”å› `CheckpointError::Corrupted`

---

## 13. æ¢å¤å®‰å…¨ç­–ç•¥ï¼ˆResume Safetyï¼‰

### 13.1 é—®é¢˜

æ£€æŸ¥ç‚¹ä¿å­˜æ—¶çš„è¿è¡Œç¯å¢ƒä¸æ¢å¤æ—¶å¯èƒ½ä¸åŒã€‚ä¾‹å¦‚ï¼š

| å˜åŒ–ç±»å‹ | ä¸¾ä¾‹ | é£é™©ç­‰çº§ |
|---------|------|---------|
| LLM Provider å˜æ›´ | ä¿å­˜æ—¶ç”¨ GPT-4oï¼Œæ¢å¤æ—¶ç”¨ GPT-3.5 | âš ï¸ ä¸­ â€” å¯èƒ½å½±å“åç»­ agent è´¨é‡ |
| å®‰å…¨çº§åˆ«é™ä½ | ä¿å­˜æ—¶ `Strict`ï¼Œæ¢å¤æ—¶ `Permissive` | ğŸ”´ é«˜ â€” æ£€æŸ¥ç‚¹ä¸­çš„å˜é‡å¯èƒ½å«æœ‰å—é™æ•°æ® |
| å®‰å…¨çº§åˆ«æå‡ | ä¿å­˜æ—¶ `Permissive`ï¼Œæ¢å¤æ—¶ `Strict` | âœ… å®‰å…¨ â€” æ›´ä¸¥æ ¼æ€»æ˜¯ OK |
| å‡­è¯å˜æ›´ | ä¿å­˜æ—¶ API Key Aï¼Œæ¢å¤æ—¶ Key B | âš ï¸ ä¸­ â€” å¯èƒ½å¯¼è‡´åç»­è°ƒç”¨å¤±è´¥ |
| ç½‘ç»œç­–ç•¥æ”¶ç´§ | ä¿å­˜æ—¶å…è®¸å¤–ç½‘ï¼Œæ¢å¤æ—¶ä»…å†…ç½‘ | âš ï¸ ä¸­ â€” åç»­ HTTP/MCP èŠ‚ç‚¹å¯èƒ½å¤±è´¥ |
| Schema ç‰ˆæœ¬å˜æ›´ | ä¿å­˜æ—¶ v1ï¼Œæ¢å¤æ—¶ v2 | ğŸ”´ é«˜ â€” DAG ç»“æ„å¯èƒ½ä¸å…¼å®¹ |

### 13.2 è®¾è®¡ï¼šä¸¤ç§æ¢å¤ç­–ç•¥

æä¾›ä¸¤ç§æ¢å¤ç­–ç•¥ï¼Œç”±è°ƒç”¨æ–¹æ˜¾å¼é€‰æ‹©ï¼š

```rust
/// æ¢å¤ç­–ç•¥
#[derive(Debug, Clone, Copy, Default)]
pub enum ResumePolicy {
    /// é»˜è®¤ç­–ç•¥ï¼šæ£€æµ‹ç¯å¢ƒå˜åŒ–ï¼Œå‘ç°å±é™©æ—¶æ‹’ç»æ¢å¤å¹¶æŠ¥å‘Šå…·ä½“å†…å®¹
    ///
    /// è°ƒç”¨æ–¹æ”¶åˆ° `ResumeRejected` é”™è¯¯åå¯ä»¥ï¼š
    /// 1. ä¿®å¤ç¯å¢ƒé—®é¢˜åé‡è¯•
    /// 2. åˆ‡æ¢ä¸º `Force` ç­–ç•¥å¼ºåˆ¶æ¢å¤
    #[default]
    Normal,

    /// å¼ºåˆ¶æ¢å¤ï¼šè·³è¿‡æ‰€æœ‰å®‰å…¨æ£€æŸ¥ï¼Œç›´æ¥ä»æ£€æŸ¥ç‚¹æ¢å¤
    ///
    /// ä»…å®¡è®¡æ—¥å¿—è®°å½•ï¼ˆå¦‚æœ AuditLogger å­˜åœ¨ï¼‰ï¼Œä¸é˜»æ­¢æ¢å¤ã€‚
    /// ç”¨äºï¼šç”¨æˆ·å·²çŸ¥ç¯å¢ƒå˜åŒ–ã€æ‰‹åŠ¨ç¡®è®¤é£é™©åçš„åœºæ™¯ã€‚
    Force,
}
```

### 13.3 ContextFingerprint â€” ç¯å¢ƒå¿«ç…§

ä¿å­˜æ£€æŸ¥ç‚¹æ—¶ï¼ŒåŒæ­¥è®°å½•å½“å‰è¿è¡Œç¯å¢ƒçš„"æŒ‡çº¹"ï¼š

```rust
/// è¿è¡Œç¯å¢ƒæŒ‡çº¹ â€” ä¿å­˜åœ¨æ£€æŸ¥ç‚¹ä¸­ï¼Œæ¢å¤æ—¶ç”¨äºæ¯”å¯¹
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct ContextFingerprint {
    /// å®‰å…¨çº§åˆ«ï¼ˆsecurity feature ä¸‹ï¼‰
    pub security_level: Option<String>,
    /// å·²æ³¨å†Œçš„ LLM Provider åç§°åˆ—è¡¨
    pub llm_providers: Vec<String>,
    /// å·²æ³¨å†Œçš„èŠ‚ç‚¹ç±»å‹åˆ—è¡¨
    pub registered_node_types: Vec<String>,
    /// ç½‘ç»œç­–ç•¥æ‘˜è¦ï¼ˆå…è®¸çš„åŸŸåæ•°ã€æ˜¯å¦æœ‰é»‘åå•ç­‰ï¼‰
    pub network_policy_hash: Option<String>,
    /// Schema çš„å†…å®¹æ‘˜è¦ï¼ˆç”¨äºæ£€æµ‹ DAG ç»“æ„å˜åŒ–ï¼‰
    pub schema_hash: String,
    /// å‡­è¯ç»„ååˆ—è¡¨ï¼ˆä¸å«å‡­è¯å†…å®¹ï¼Œä»…åç§°ç”¨äºæ¯”å¯¹å¯ç”¨æ€§ï¼‰
    pub credential_groups: Vec<String>,
    /// å¼•æ“é…ç½®æ‘˜è¦
    pub engine_config_hash: String,
}
```

**é‡‡é›†æ—¶æœº**ï¼šåœ¨ `save_checkpoint()` ä¸­ï¼Œä¸ DAG çŠ¶æ€å’Œå˜é‡ä¸€èµ·ä¿å­˜ã€‚

```rust
impl ContextFingerprint {
    /// ä»å½“å‰è¿è¡Œç¯å¢ƒé‡‡é›†æŒ‡çº¹
    pub fn capture(context: &WorkflowContext, schema: &WorkflowSchema) -> Self {
        let runtime = &context.runtime_group;
        Self {
            security_level: runtime.security_level().map(|l| format!("{:?}", l)),
            llm_providers: runtime.llm_provider_registry()
                .map(|r| r.list_providers())
                .unwrap_or_default(),
            registered_node_types: runtime.node_executor_registry()
                .list_registered_types(),
            network_policy_hash: runtime.network_policy()
                .map(|p| p.summary_hash()),
            schema_hash: schema.content_hash(),
            credential_groups: runtime.credential_provider()
                .map(|p| p.list_groups())
                .unwrap_or_default(),
            engine_config_hash: context.engine_config_hash(),
        }
    }
}
```

### 13.4 Checkpoint ç»“æ„æ–°å¢å­—æ®µ

åœ¨ `Checkpoint` ä¸­æ–°å¢ï¼š

```rust
pub struct Checkpoint {
    // ... ç°æœ‰å­—æ®µ ...

    /// ä¿å­˜æ—¶çš„è¿è¡Œç¯å¢ƒæŒ‡çº¹ï¼ˆç”¨äºæ¢å¤æ—¶å®‰å…¨æ¯”å¯¹ï¼‰
    pub context_fingerprint: Option<ContextFingerprint>,
}
```

ä½¿ç”¨ `Option<ContextFingerprint>` ä»¥å…¼å®¹æ—§ç‰ˆæ£€æŸ¥ç‚¹ï¼ˆæ²¡æœ‰æŒ‡çº¹çš„æ£€æŸ¥ç‚¹åœ¨ Normal ç­–ç•¥ä¸‹ä¼šè¢«æ ‡è®°ä¸º warningï¼‰ã€‚

### 13.5 ResumeDiagnostic â€” å·®å¼‚æ£€æµ‹

æ¢å¤æ—¶å°†å½“å‰ç¯å¢ƒä¸æ£€æŸ¥ç‚¹ä¸­çš„æŒ‡çº¹æ¯”å¯¹ï¼Œç”Ÿæˆè¯Šæ–­æŠ¥å‘Šï¼š

```rust
/// å•é¡¹ç¯å¢ƒå·®å¼‚
#[derive(Debug, Clone)]
pub struct EnvironmentChange {
    /// å˜åŒ–çš„ç»„ä»¶
    pub component: String,
    /// å…·ä½“æè¿°
    pub description: String,
    /// é£é™©ç­‰çº§
    pub severity: ChangeSeverity,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum ChangeSeverity {
    /// ä¿¡æ¯ï¼šå˜åŒ–å®‰å…¨æˆ–ä¸­æ€§
    Info,
    /// è­¦å‘Šï¼šå¯èƒ½å½±å“åç»­æ‰§è¡Œ
    Warning,
    /// å±é™©ï¼šå®‰å…¨é™çº§æˆ–ç»“æ„ä¸å…¼å®¹
    Danger,
}

/// æ¢å¤è¯Šæ–­æŠ¥å‘Š
#[derive(Debug, Clone)]
pub struct ResumeDiagnostic {
    /// æ£€æµ‹åˆ°çš„æ‰€æœ‰ç¯å¢ƒå˜åŒ–
    pub changes: Vec<EnvironmentChange>,
}

impl ResumeDiagnostic {
    /// æ˜¯å¦åŒ…å«å±é™©å˜åŒ–
    pub fn has_danger(&self) -> bool {
        self.changes.iter().any(|c| c.severity == ChangeSeverity::Danger)
    }

    /// æ˜¯å¦åŒ…å«è­¦å‘Šæˆ–å±é™©
    pub fn has_warnings(&self) -> bool {
        self.changes.iter().any(|c| {
            matches!(c.severity, ChangeSeverity::Warning | ChangeSeverity::Danger)
        })
    }

    /// ç”Ÿæˆäººç±»å¯è¯»çš„æŠ¥å‘Š
    pub fn report(&self) -> String {
        let mut lines = Vec::new();
        for change in &self.changes {
            let icon = match change.severity {
                ChangeSeverity::Info => "â„¹ï¸",
                ChangeSeverity::Warning => "âš ï¸",
                ChangeSeverity::Danger => "ğŸ”´",
            };
            lines.push(format!("{} [{}] {}", icon, change.component, change.description));
        }
        lines.join("\n")
    }
}
```

### 13.6 æ¯”å¯¹é€»è¾‘

```rust
/// æ¯”å¯¹æ£€æŸ¥ç‚¹æŒ‡çº¹ä¸å½“å‰ç¯å¢ƒ
pub fn diff_fingerprints(
    saved: &ContextFingerprint,
    current: &ContextFingerprint,
) -> ResumeDiagnostic {
    let mut changes = Vec::new();

    // 1. Schema ç»“æ„å˜åŒ– â†’ Danger
    if saved.schema_hash != current.schema_hash {
        changes.push(EnvironmentChange {
            component: "schema".into(),
            description: "Workflow schema has changed since checkpoint was saved. \
                          DAG structure may be incompatible.".into(),
            severity: ChangeSeverity::Danger,
        });
    }

    // 2. å®‰å…¨çº§åˆ«å˜åŒ–
    match (&saved.security_level, &current.security_level) {
        (Some(saved_level), Some(current_level)) if saved_level != current_level => {
            let severity = if is_security_downgrade(saved_level, current_level) {
                ChangeSeverity::Danger
            } else {
                ChangeSeverity::Info  // å‡çº§æ˜¯å®‰å…¨çš„
            };
            changes.push(EnvironmentChange {
                component: "security_level".into(),
                description: format!(
                    "Security level changed: {} â†’ {}",
                    saved_level, current_level
                ),
                severity,
            });
        }
        (Some(_), None) => {
            changes.push(EnvironmentChange {
                component: "security_level".into(),
                description: "Security was enabled at checkpoint time but is now disabled.".into(),
                severity: ChangeSeverity::Danger,
            });
        }
        _ => {}
    }

    // 3. LLM Provider å˜åŒ–
    let removed_providers: Vec<_> = saved.llm_providers.iter()
        .filter(|p| !current.llm_providers.contains(p))
        .collect();
    if !removed_providers.is_empty() {
        changes.push(EnvironmentChange {
            component: "llm_providers".into(),
            description: format!(
                "LLM providers removed since checkpoint: [{}]. \
                 Subsequent LLM/agent nodes using these providers will fail.",
                removed_providers.iter().map(|s| s.as_str()).collect::<Vec<_>>().join(", ")
            ),
            severity: ChangeSeverity::Warning,
        });
    }

    // 4. èŠ‚ç‚¹ç±»å‹ç¼ºå¤±
    let removed_types: Vec<_> = saved.registered_node_types.iter()
        .filter(|t| !current.registered_node_types.contains(t))
        .collect();
    if !removed_types.is_empty() {
        changes.push(EnvironmentChange {
            component: "node_types".into(),
            description: format!(
                "Node types removed: [{}]. Pending nodes of these types will fail.",
                removed_types.iter().map(|s| s.as_str()).collect::<Vec<_>>().join(", ")
            ),
            severity: ChangeSeverity::Danger,
        });
    }

    // 5. ç½‘ç»œç­–ç•¥å˜åŒ–
    if saved.network_policy_hash != current.network_policy_hash {
        changes.push(EnvironmentChange {
            component: "network_policy".into(),
            description: "Network policy has changed. HTTP/MCP nodes may be \
                          blocked by new restrictions.".into(),
            severity: ChangeSeverity::Warning,
        });
    }

    // 6. å‡­è¯ç»„å˜åŒ–
    let removed_creds: Vec<_> = saved.credential_groups.iter()
        .filter(|g| !current.credential_groups.contains(g))
        .collect();
    if !removed_creds.is_empty() {
        changes.push(EnvironmentChange {
            component: "credentials".into(),
            description: format!(
                "Credential groups no longer available: [{}].",
                removed_creds.iter().map(|s| s.as_str()).collect::<Vec<_>>().join(", ")
            ),
            severity: ChangeSeverity::Warning,
        });
    }

    // 7. å¼•æ“é…ç½®å˜åŒ–
    if saved.engine_config_hash != current.engine_config_hash {
        changes.push(EnvironmentChange {
            component: "engine_config".into(),
            description: "Engine configuration has changed (max_steps, timeout, etc.).".into(),
            severity: ChangeSeverity::Info,
        });
    }

    ResumeDiagnostic { changes }
}

/// åˆ¤æ–­å®‰å…¨çº§åˆ«æ˜¯å¦ä¸ºé™çº§
fn is_security_downgrade(saved: &str, current: &str) -> bool {
    let level_order = ["Strict", "Standard", "Permissive"];
    let saved_idx = level_order.iter().position(|&l| l == saved);
    let current_idx = level_order.iter().position(|&l| l == current);
    match (saved_idx, current_idx) {
        (Some(s), Some(c)) => c > s,  // æ•°å€¼è¶Šå¤§è¶Šå®½æ¾ = é™çº§
        _ => false,
    }
}
```

### 13.7 æ¢å¤æµç¨‹é›†æˆ

ä¿®æ”¹ `try_resume_from_checkpoint()` ä»¥æ”¯æŒæ¢å¤ç­–ç•¥ï¼š

```rust
impl<G: DebugGate, H: DebugHook> WorkflowDispatcher<G, H> {
    async fn try_resume_from_checkpoint(
        &mut self,
        resume_policy: ResumePolicy,
    ) -> WorkflowResult<Option<(Vec<String>, HashMap<String, String>, i32, i64)>> {
        let Some(store) = &self.checkpoint_store else {
            return Ok(None);
        };

        let Some(cp) = store.load(&self.workflow_id).await
            .map_err(|e| WorkflowError::InternalError(
                format!("Checkpoint load failed: {}", e)
            ))?
        else {
            return Ok(None);
        };

        // === ç¯å¢ƒå®‰å…¨æ£€æŸ¥ ===
        let current_fingerprint = ContextFingerprint::capture(
            &self.context, &self.schema
        );

        match resume_policy {
            ResumePolicy::Normal => {
                if let Some(saved_fp) = &cp.context_fingerprint {
                    let diagnostic = diff_fingerprints(saved_fp, &current_fingerprint);
                    if diagnostic.has_danger() {
                        // æ‹’ç»æ¢å¤ï¼Œè¿”å›è¯¦ç»†çš„è¯Šæ–­æŠ¥å‘Š
                        return Err(WorkflowError::ResumeRejected {
                            workflow_id: self.workflow_id.clone(),
                            diagnostic: diagnostic.report(),
                            changes: diagnostic.changes,
                        });
                    }
                    if diagnostic.has_warnings() {
                        // æœ‰è­¦å‘Šä½†æ— å±é™©ï¼šè®°å½•å®¡è®¡æ—¥å¿—ï¼Œç»§ç»­æ¢å¤
                        self.event_emitter.emit(GraphEngineEvent::ResumeWarning {
                            diagnostic: diagnostic.report(),
                        }).await;
                    }
                } else {
                    // æ—§ç‰ˆæ£€æŸ¥ç‚¹æ— æŒ‡çº¹ï¼šè®°å½•è­¦å‘Šï¼Œå…è®¸æ¢å¤
                    self.event_emitter.emit(GraphEngineEvent::ResumeWarning {
                        diagnostic: "Checkpoint has no context fingerprint \
                                    (legacy format). Safety check skipped.".into(),
                    }).await;
                }
            }
            ResumePolicy::Force => {
                // å¼ºåˆ¶æ¢å¤ï¼šè·³è¿‡æ‰€æœ‰å®‰å…¨æ£€æŸ¥ï¼Œä»…è®°å½•å®¡è®¡æ—¥å¿—
                if let Some(saved_fp) = &cp.context_fingerprint {
                    let diagnostic = diff_fingerprints(saved_fp, &current_fingerprint);
                    if diagnostic.has_warnings() {
                        // ä»…å†™å®¡è®¡æ—¥å¿—ï¼Œä¸é˜»æ­¢
                        #[cfg(feature = "security")]
                        if let Some(logger) = self.context.runtime_group.audit_logger() {
                            logger.log(AuditEvent::ForceResumeWithChanges {
                                workflow_id: self.workflow_id.clone(),
                                changes: diagnostic.report(),
                            }).await;
                        }
                    }
                }
                // æ— è®ºæœ‰æ— å·®å¼‚ï¼Œç»§ç»­æ¢å¤
            }
        }

        // === æ¢å¤çŠ¶æ€ï¼ˆä¸ä¹‹å‰ç›¸åŒï¼‰ ===
        // æ¢å¤ Graphã€VariablePoolã€æ‰§è¡Œå…ƒæ•°æ® ...
        // ï¼ˆåŒ 4.4 èŠ‚ï¼‰

        Ok(Some((cp.ready_queue, cp.ready_predecessor, cp.step_count, adjusted_start)))
    }
}
```

### 13.8 WorkflowRunnerBuilder æ–°å¢æ–¹æ³•

```rust
impl WorkflowRunnerBuilder {
    /// è®¾ç½®æ¢å¤ç­–ç•¥ï¼ˆä»…åœ¨æœ‰æ£€æŸ¥ç‚¹æ—¶ç”Ÿæ•ˆï¼‰
    ///
    /// - `Normal`ï¼ˆé»˜è®¤ï¼‰ï¼šæ£€æµ‹ç¯å¢ƒå˜åŒ–ï¼Œå±é™©æ—¶æ‹’ç»æ¢å¤å¹¶æŠ¥å‘Š
    /// - `Force`ï¼šè·³è¿‡å®‰å…¨æ£€æŸ¥ï¼Œç›´æ¥æ¢å¤
    pub fn resume_policy(mut self, policy: ResumePolicy) -> Self {
        self.resume_policy = policy;
        self
    }
}
```

### 13.9 CheckpointError æ‰©å±•

```rust
#[derive(Debug, thiserror::Error)]
pub enum CheckpointError {
    // ... ç°æœ‰ variants ...

    #[error("Resume rejected for workflow '{workflow_id}':\n{diagnostic}")]
    ResumeRejected {
        workflow_id: String,
        diagnostic: String,
    },
}
```

### 13.10 è°ƒç”¨æ–¹ä½¿ç”¨ç¤ºä¾‹

#### é»˜è®¤æ¢å¤ï¼ˆNormal â€” æ£€æµ‹å±é™©ï¼‰

```rust
let handle = WorkflowRunner::builder(schema)
    .checkpoint_store(store.clone())
    .workflow_id("order-12345".to_string())
    // resume_policy é»˜è®¤ä¸º Normal
    .build()
    .run()
    .await;

match handle {
    Err(WorkflowError::ResumeRejected { diagnostic, .. }) => {
        // ç¯å¢ƒå˜åŒ–è¢«æ£€æµ‹åˆ°ï¼Œå‘ç”¨æˆ·å±•ç¤ºå…·ä½“çš„å±é™©å†…å®¹
        eprintln!("Cannot resume safely:\n{}", diagnostic);
        // è¾“å‡ºç¤ºä¾‹ï¼š
        // ğŸ”´ [security_level] Security level changed: Strict â†’ Permissive
        // ğŸ”´ [schema] Workflow schema has changed since checkpoint was saved.
        // âš ï¸ [llm_providers] LLM providers removed: [openai].

        // ç”¨æˆ·ç¡®è®¤åï¼Œå¯ä»¥é€‰æ‹©å¼ºåˆ¶æ¢å¤ï¼š
        let handle = WorkflowRunner::builder(schema)
            .checkpoint_store(store.clone())
            .workflow_id("order-12345".to_string())
            .resume_policy(ResumePolicy::Force)
            .build()
            .run()
            .await?;
    }
    Ok(handle) => {
        // æ­£å¸¸æ¢å¤æˆ–æ— æ£€æŸ¥ç‚¹ï¼Œç»§ç»­æ‰§è¡Œ
        let status = handle.wait().await;
    }
    Err(e) => {
        eprintln!("Other error: {}", e);
    }
}
```

#### å¼ºåˆ¶æ¢å¤ï¼ˆForce â€” è·³è¿‡å®‰å…¨æ£€æŸ¥ï¼‰

```rust
// å·²çŸ¥ç¯å¢ƒå˜åŒ–ï¼Œç”¨æˆ·æ‰‹åŠ¨ç¡®è®¤é£é™©
let handle = WorkflowRunner::builder(schema)
    .checkpoint_store(store.clone())
    .workflow_id("order-12345".to_string())
    .resume_policy(ResumePolicy::Force)  // æ˜¾å¼å¼ºåˆ¶
    .build()
    .run()
    .await?;

// å³ä½¿å®‰å…¨çº§åˆ«é™ä½ã€Provider å˜æ›´ï¼Œä¹Ÿç›´æ¥æ¢å¤
// ä½†æ‰€æœ‰å˜åŒ–ä¼šè¢«è®°å½•åˆ°å®¡è®¡æ—¥å¿—
```

### 13.11 è¡Œä¸ºæ€»ç»“

| åœºæ™¯ | Normal ç­–ç•¥ | Force ç­–ç•¥ |
|------|------------|-----------|
| æ— ç¯å¢ƒå˜åŒ– | âœ… æ­£å¸¸æ¢å¤ | âœ… æ­£å¸¸æ¢å¤ |
| å®‰å…¨çº§åˆ«å‡çº§ï¼ˆæ›´ä¸¥æ ¼ï¼‰ | âœ… æ­£å¸¸æ¢å¤ï¼ˆInfo æ—¥å¿—ï¼‰ | âœ… æ­£å¸¸æ¢å¤ |
| å®‰å…¨çº§åˆ«é™çº§ï¼ˆæ›´å®½æ¾ï¼‰ | ğŸ”´ **æ‹’ç»æ¢å¤** + æŠ¥å‘Šè¯¦æƒ… | âœ… æ¢å¤ + å®¡è®¡æ—¥å¿— |
| Security è¢«ç¦ç”¨ | ğŸ”´ **æ‹’ç»æ¢å¤** + æŠ¥å‘Šè¯¦æƒ… | âœ… æ¢å¤ + å®¡è®¡æ—¥å¿— |
| Schema å˜æ›´ | ğŸ”´ **æ‹’ç»æ¢å¤** + æŠ¥å‘Šè¯¦æƒ… | âœ… æ¢å¤ + å®¡è®¡æ—¥å¿— |
| LLM Provider ç¼ºå¤± | âš ï¸ è­¦å‘Šæ—¥å¿—ï¼Œå…è®¸æ¢å¤ | âœ… æ¢å¤ + å®¡è®¡æ—¥å¿— |
| å‡­è¯ç»„ç¼ºå¤± | âš ï¸ è­¦å‘Šæ—¥å¿—ï¼Œå…è®¸æ¢å¤ | âœ… æ¢å¤ + å®¡è®¡æ—¥å¿— |
| ç½‘ç»œç­–ç•¥å˜åŒ– | âš ï¸ è­¦å‘Šæ—¥å¿—ï¼Œå…è®¸æ¢å¤ | âœ… æ¢å¤ + å®¡è®¡æ—¥å¿— |
| å¼•æ“é…ç½®å˜åŒ– | âœ… Info æ—¥å¿—ï¼Œæ­£å¸¸æ¢å¤ | âœ… æ­£å¸¸æ¢å¤ |
| æ—§ç‰ˆæ£€æŸ¥ç‚¹ï¼ˆæ— æŒ‡çº¹ï¼‰ | âš ï¸ è­¦å‘Šæ—¥å¿—ï¼Œå…è®¸æ¢å¤ | âœ… æ­£å¸¸æ¢å¤ |

**è®¾è®¡åŸåˆ™**ï¼š
- **Normal ç­–ç•¥**åªåœ¨æ£€æµ‹åˆ° `Danger` çº§åˆ«å˜åŒ–æ—¶æ‹’ç»æ¢å¤ï¼Œ`Warning` çº§åˆ«ä»…è®°å½•æ—¥å¿—
- **Force ç­–ç•¥**æ°¸è¿œä¸é˜»æ­¢æ¢å¤ï¼Œä½†æ‰€æœ‰å˜åŒ–éƒ½å†™å®¡è®¡æ—¥å¿—ï¼ˆå¯è¿½æº¯ï¼‰
- è°ƒç”¨æ–¹æ”¶åˆ° `ResumeRejected` åæ‹¿åˆ°å®Œæ•´çš„è¯Šæ–­æŠ¥å‘Šï¼Œå¯ä»¥å‘ç»ˆç«¯ç”¨æˆ·å±•ç¤ºå…·ä½“å†…å®¹
- ç”¨æˆ·çœ‹åˆ°å…·ä½“é£é™©åè‡ªè¡Œå†³å®šæ˜¯å¦ Force æ¢å¤ â€” ç³»ç»Ÿä¸åšäºŒæ¬¡ç¡®è®¤

---

## 14. æµ‹è¯•ç­–ç•¥

### 14.1 å•å…ƒæµ‹è¯•

| æµ‹è¯• | éªŒè¯å†…å®¹ |
|------|---------|
| `test_checkpoint_save_load` | MemoryStore save â†’ load â†’ æ•°æ®ä¸€è‡´ |
| `test_checkpoint_delete` | save â†’ delete â†’ load returns None |
| `test_checkpoint_overwrite` | save twice â†’ load returns latest |
| `test_snapshot_for_checkpoint` | VariablePool å«å„ç§ Segment ç±»å‹ â†’ Value è½¬æ¢æ­£ç¡® |
| `test_snapshot_skips_streams` | å«æœªå®Œæˆ Stream â†’ è¢«è·³è¿‡ |
| `test_restore_from_checkpoint` | Value â†’ VariablePool â†’ è¯»å–æ­£ç¡® |
| `test_serializable_edge_state` | åŒå‘è½¬æ¢æ­£ç¡® |
| `test_context_fingerprint_capture` | ä» WorkflowContext é‡‡é›†æŒ‡çº¹ï¼Œå­—æ®µæ­£ç¡® |
| `test_diff_fingerprints_no_change` | ç›¸åŒæŒ‡çº¹ â†’ æ— å˜åŒ– |
| `test_diff_fingerprints_security_downgrade` | å®‰å…¨çº§åˆ«é™çº§ â†’ Danger |
| `test_diff_fingerprints_security_upgrade` | å®‰å…¨çº§åˆ«å‡çº§ â†’ Info |
| `test_diff_fingerprints_provider_removed` | LLM Provider ç¼ºå¤± â†’ Warning |
| `test_diff_fingerprints_schema_changed` | Schema å˜æ›´ â†’ Danger |
| `test_resume_normal_rejects_danger` | Normal ç­–ç•¥ + Danger å˜åŒ– â†’ ResumeRejected |
| `test_resume_force_allows_danger` | Force ç­–ç•¥ + Danger å˜åŒ– â†’ æ­£å¸¸æ¢å¤ |

### 14.2 é›†æˆæµ‹è¯•

#### Case 140: `checkpoint_basic`

- workflow: `start â†’ code â†’ agent(mock) â†’ end`
- é…ç½® MemoryCheckpointStore
- éªŒè¯ï¼šagent å®Œæˆåæ£€æŸ¥ç‚¹å­˜åœ¨ï¼Œworkflow å®Œæˆåæ£€æŸ¥ç‚¹è¢«åˆ é™¤

#### Case 141: `checkpoint_resume`

- ç¬¬ä¸€æ¬¡è¿è¡Œï¼šagent æˆåŠŸ â†’ ä¸‹ä¸€ä¸ªèŠ‚ç‚¹äººä¸ºæŠ¥é”™
- ç¬¬äºŒæ¬¡è¿è¡Œï¼šåŒä¸€ workflow_id â†’ ä» agent ä¹‹åæ¢å¤
- éªŒè¯ï¼šagent ä¸é‡è·‘ï¼Œæœ€ç»ˆè¾“å‡ºæ­£ç¡®

#### Case 142: `human_input_pause_resume`

- workflow: `start â†’ human-input â†’ end`
- éªŒè¯ï¼šstatus å˜ä¸º Paused â†’ resume_with_input â†’ Completed

#### Case 143: `checkpoint_file_store`

- ä½¿ç”¨ FileCheckpointStore + ä¸´æ—¶ç›®å½•
- éªŒè¯ï¼šæ–‡ä»¶åˆ›å»º/è¯»å–/åˆ é™¤æ­£ç¡®

#### Case 144: `resume_safety_normal_rejects`

- ç¬¬ä¸€æ¬¡è¿è¡Œï¼šsecurity_level=Strictï¼Œagent æˆåŠŸåä¿å­˜æ£€æŸ¥ç‚¹
- ç¬¬äºŒæ¬¡è¿è¡Œï¼šsecurity_level=Permissiveï¼ŒNormal ç­–ç•¥
- éªŒè¯ï¼šè¿”å› `ResumeRejected` + diagnostic åŒ…å« "security_level" å’Œ "Strict â†’ Permissive"

#### Case 145: `resume_safety_force_allows`

- åŒ Case 144 çš„åœºæ™¯ï¼Œä½†ä½¿ç”¨ `ResumePolicy::Force`
- éªŒè¯ï¼šæ­£å¸¸æ¢å¤ï¼Œå®¡è®¡æ—¥å¿—ä¸­è®°å½•äº† ForceResumeWithChanges

---

## 15. æ–‡ä»¶å˜æ›´æ¸…å•

| æ–‡ä»¶ | æ“ä½œ | è¯´æ˜ |
|------|------|------|
| `src/core/checkpoint.rs` | **æ–°å»º** | CheckpointStore trait, Checkpoint, CheckpointError, ContextFingerprint, ResumeDiagnostic, ResumePolicy, diff_fingerprints(), åºåˆ—åŒ–è¾…åŠ©å‡½æ•°, SafeStopSignal, å†…ç½® Store å®ç° |
| `src/core/mod.rs` | ä¿®æ”¹ | æ·»åŠ  `#[cfg(feature = "checkpoint")] pub mod checkpoint` |
| `src/core/dispatcher.rs` | ä¿®æ”¹ | æ·»åŠ  checkpoint_store å­—æ®µã€save/resume/delete æ–¹æ³•ã€run() ä¸­ä¸¤å¤„è°ƒç”¨ |
| `src/core/event_bus.rs` | ä¿®æ”¹ | æ·»åŠ  CheckpointSaved/Resumed/WorkflowPaused/Resumed äº‹ä»¶ |
| `src/core/variable_pool.rs` | ä¿®æ”¹ | æ·»åŠ  `snapshot_for_checkpoint()` å’Œ `restore_from_checkpoint()` |
| `src/scheduler.rs` | ä¿®æ”¹ | ExecutionStatus::Paused, WorkflowHandle::resume_with_input/wait_or_paused, Builder::checkpoint_store |
| `src/nodes/human_input.rs` | **æ–°å»º** | HumanInputExecutor |
| `src/nodes/executor.rs` | ä¿®æ”¹ | æ³¨å†Œ human-inputï¼ˆæ›¿æ¢ stubï¼‰ |
| `Cargo.toml` | ä¿®æ”¹ | æ·»åŠ  `checkpoint` feature |

---

## 16. å®æ–½é¡ºåº

1. `src/core/checkpoint.rs` â€” å®šä¹‰ trait å’Œæ•°æ®ç»“æ„ï¼ˆå« ContextFingerprint, ResumePolicyï¼‰
2. `src/core/variable_pool.rs` â€” æ·»åŠ  `snapshot_for_checkpoint` / `restore_from_checkpoint`
3. `src/core/event_bus.rs` â€” æ–°å¢äº‹ä»¶ç±»å‹ï¼ˆå« ResumeWarningï¼‰
4. `src/core/dispatcher.rs` â€” é›†æˆæ£€æŸ¥ç‚¹é€»è¾‘ï¼ˆsave/resume/delete + æ¢å¤å®‰å…¨æ£€æŸ¥ï¼‰
5. `src/scheduler.rs` â€” ExecutionStatus::Paused + WorkflowHandle æ–¹æ³• + resume_policy
6. `src/nodes/human_input.rs` â€” HumanInputExecutor
7. MemoryCheckpointStore å†…ç½®å®ç°
8. FileCheckpointStore å†…ç½®å®ç°
9. SafeStopSignal + execute_safe_stop
10. å•å…ƒæµ‹è¯• + é›†æˆæµ‹è¯•ï¼ˆå« resume safety casesï¼‰

---

## 17. éªŒè¯å‘½ä»¤

```bash
# æ„å»ºå«æ£€æŸ¥ç‚¹
cargo build --features checkpoint

# å…¨é‡æ„å»º
cargo build --all-features

# æµ‹è¯•
cargo test --all-features --workspace --lib checkpoint
cargo test --all-features --workspace --lib human_input
cargo test --all-features --workspace --test integration_tests -- 140
cargo test --all-features --workspace --test integration_tests -- 141
cargo test --all-features --workspace --test integration_tests -- 142
cargo test --all-features --workspace --test integration_tests -- 143
cargo test --all-features --workspace --test integration_tests -- 144
cargo test --all-features --workspace --test integration_tests -- 145
cargo test --all-features --workspace
cargo clippy --all-features --workspace
```

---

## 18. è®¾è®¡æ€»ç»“

```
ä¸é…ç½® checkpoint_store æ—¶ï¼š
  è¡Œä¸ºä¸ç°åœ¨å®Œå…¨ä¸€è‡´ â† é›¶å¼€é”€ï¼Œé›¶ç ´å

é…ç½® checkpoint_store æ—¶ï¼š
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  run() å¼€å§‹                               â”‚
  â”‚  â”œâ”€ æœ‰æ£€æŸ¥ç‚¹ï¼Ÿ â†’ æ¢å¤çŠ¶æ€ï¼Œè·³è¿‡å·²å®ŒæˆèŠ‚ç‚¹   â”‚
  â”‚  â”œâ”€ æ— æ£€æŸ¥ç‚¹ï¼Ÿ â†’ æ­£å¸¸ä» start å¼€å§‹         â”‚
  â”‚  â”‚                                         â”‚
  â”‚  â”‚  æ‰§è¡Œå¾ªç¯                               â”‚
  â”‚  â”‚  â”œâ”€ èŠ‚ç‚¹å®Œæˆå                          â”‚
  â”‚  â”‚  â”‚  â”œâ”€ agent èŠ‚ç‚¹ï¼Ÿ      â†’ è‡ªåŠ¨å­˜æ£€æŸ¥ç‚¹  â”‚
  â”‚  â”‚  â”‚  â”œâ”€ human-input èŠ‚ç‚¹ï¼Ÿ â†’ å­˜æ£€æŸ¥ç‚¹+æš‚åœâ”‚
  â”‚  â”‚  â”‚  â”œâ”€ ç”¨æˆ·æ ‡è®° checkpoint? â†’ å­˜æ£€æŸ¥ç‚¹   â”‚
  â”‚  â”‚  â”‚  â””â”€ å…¶ä»–ï¼Ÿ            â†’ ä¸å­˜          â”‚
  â”‚  â”‚  â””â”€ ç»§ç»­...                             â”‚
  â”‚  â”‚                                         â”‚
  â”‚  â”œâ”€ æ­£å¸¸å®Œæˆ â†’ åˆ é™¤æ£€æŸ¥ç‚¹                   â”‚
  â”‚  â””â”€ å¼‚å¸¸é€€å‡º â†’ æ£€æŸ¥ç‚¹ä¿ç•™ï¼Œä¸‹æ¬¡å¯æ¢å¤       â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

æ ¸å¿ƒè®¾è®¡ç‰¹å¾ï¼š
- **é€‰æ‹©æ€§**ï¼šåªå­˜é«˜ä»·å€¼èŠ‚ç‚¹ï¼Œä¸æ˜¯æ¯æ­¥éƒ½å­˜
- **å¯é€‰çš„**ï¼šä¸é…ç½®æ—¶é›¶å¼€é”€ï¼Œè¡Œä¸ºä¸å˜
- **trait åŒ–**ï¼šå­˜å‚¨ç”±åµŒå…¥æ–¹å†³å®šï¼Œå¼•æ“ä¸å¼ºä¾èµ–
- **æœ€å°ä¾µå…¥**ï¼šdispatcher ä»…æ–°å¢ ~50 è¡Œæ ¸å¿ƒé€»è¾‘
- **æ¢å¤å®‰å…¨**ï¼šNormal ç­–ç•¥æ£€æµ‹ç¯å¢ƒå˜åŒ–å¹¶æŠ¥å‘Šå…·ä½“é£é™©ï¼ŒForce ç­–ç•¥è·³è¿‡æ£€æŸ¥ä½†è®°å½•å®¡è®¡æ—¥å¿—
