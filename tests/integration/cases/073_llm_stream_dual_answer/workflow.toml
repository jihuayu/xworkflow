# LLM stream dual answer: two answer nodes consume the same stream.
# File: Workflow DSL definition

version = "0.1.0"
[[nodes]]
id = "start"

[nodes.data]
type = "start"
title = "Start"
[[nodes.data.variables]]
variable = "q1"
label = "Q1"
type = "string"
required = true

[[nodes.data.variables]]
variable = "q2"
label = "Q2"
type = "string"
required = true

[[nodes]]
id = "llm1"

[nodes.data]
type = "llm"
title = "LLM1"
stream = true
[[nodes.data.prompt_template]]
role = "user"
text = "{{#start.q1#}}"

[nodes.data.model]
provider = "openai"
name = "gpt-4o"
[[nodes]]
id = "llm2"

[nodes.data]
type = "llm"
title = "LLM2"
stream = true
[[nodes.data.prompt_template]]
role = "user"
text = "{{#start.q2#}}"

[nodes.data.model]
provider = "openai"
name = "gpt-4o"
[[nodes]]
id = "ans"

[nodes.data]
type = "answer"
title = "Answer"
answer = "A={{#llm1.text#}} B={{#llm2.text#}}"
[[nodes]]
id = "end"

[nodes.data]
type = "end"
title = "End"
[[nodes.data.outputs]]
variable = "result"
value_selector = [ "ans", "answer",]

[[edges]]
source = "start"
target = "llm1"

[[edges]]
source = "start"
target = "llm2"

[[edges]]
source = "llm1"
target = "ans"

[[edges]]
source = "llm2"
target = "ans"

[[edges]]
source = "ans"
target = "end"

