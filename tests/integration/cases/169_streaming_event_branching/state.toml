# Streaming: Event bus propagation through conditional branches.
# File: Runtime state: engine config, mock server, fake time/id, etc.

[[llm_mock]]
model = "gpt-3.5-turbo"
stream_chunks = ["Stream ", "content"]
