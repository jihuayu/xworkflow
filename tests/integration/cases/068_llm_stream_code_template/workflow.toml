# LLM stream code template: code node with template processing on stream output.
# File: Workflow DSL definition

version = "0.1.0"
[[nodes]]
id = "start"

[nodes.data]
type = "start"
title = "Start"
[[nodes.data.variables]]
variable = "query"
label = "Query"
type = "string"
required = true

[[nodes]]
id = "llm1"

[nodes.data]
type = "llm"
title = "LLM Streaming"
stream = true
[[nodes.data.prompt_template]]
role = "user"
text = "{{#start.query#}}"

[nodes.data.model]
provider = "openai"
name = "gpt-4o"
[[nodes]]
id = "code1"

[nodes.data]
type = "code"
title = "Uppercase Chunks"
language = "javascript"
code = "function main(inputs) { var acc = ''; inputs.text.on_chunk(function(chunk) { var upper = chunk.toUpperCase(); acc = acc + upper; return upper; }).on_end(function(val) { return acc; }); return ''; }"
[[nodes.data.variables]]
variable = "text"
value_selector = [ "llm1", "text",]

[[nodes]]
id = "tmpl"

[nodes.data]
type = "template-transform"
title = "Wrap Result"
template = "[{{ text }}]"
[[nodes.data.variables]]
variable = "text"
value_selector = [ "code1", "output",]

[[nodes]]
id = "end"

[nodes.data]
type = "end"
title = "End"
[[nodes.data.outputs]]
variable = "result"
value_selector = [ "tmpl", "output",]

[[edges]]
source = "start"
target = "llm1"

[[edges]]
source = "llm1"
target = "code1"

[[edges]]
source = "code1"
target = "tmpl"

[[edges]]
source = "tmpl"
target = "end"

