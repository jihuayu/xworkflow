# LLM stream answer mixed: answer node consumes both stream and plain data.
# File: Expected execution result and output values

status = "completed"

[outputs]
result = "Bot - Hey buddy"
