# LLM stream answer mixed: answer node consumes both stream and plain data.
# File: Input variables supplied to the workflow

query = "hi"
prefix = "Bot"
