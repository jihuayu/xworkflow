# Streaming: Multiple LLM nodes with streaming propagation.
# File: Workflow DSL definition

version = "0.1.0"
[[nodes]]
id = "start"

[nodes.data]
type = "start"
title = "Start"
[[nodes.data.variables]]
variable = "prompt1"
label = "Prompt 1"
type = "string"
required = true

[[nodes]]
id = "llm1"

[nodes.data]
type = "llm"
title = "First LLM"
model = "gpt-3.5-turbo"
prompt_template = "{{#start.prompt1#}}"
enable_streaming = true

[[nodes]]
id = "template1"

[nodes.data]
type = "template-transform"
title = "Format"
template = "Step 1 result: {{#llm1.output#}}"

[[nodes]]
id = "llm2"

[nodes.data]
type = "llm"
title = "Second LLM"
model = "gpt-3.5-turbo"
prompt_template = "Summarize: {{#template1.output#}}"
enable_streaming = true

[[nodes]]
id = "end"

[nodes.data]
type = "end"
title = "End"
[[nodes.data.outputs]]
variable = "final"
value_selector = [ "llm2", "output",]

[[edges]]
source = "start"
target = "llm1"

[[edges]]
source = "llm1"
target = "template1"

[[edges]]
source = "template1"
target = "llm2"

[[edges]]
source = "llm2"
target = "end"
